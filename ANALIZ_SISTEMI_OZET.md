# MergenLite Analiz Sistemi - NasÄ±l Ã‡alÄ±ÅŸÄ±yor?

## ğŸ” Mevcut Durum

### LLM KullanÄ±mÄ±
- **Ana Pipeline**: `mergenlite_opportunity_pipeline.py` â†’ **Sadece OpenAI** kullanÄ±yor
- **LLM Analyzer**: `llm_analyzer.py` â†’ **Sadece OpenAI** kullanÄ±yor
- **Ollama**: Åu anda **kullanÄ±lmÄ±yor** (eski dosyalarda referans var ama aktif deÄŸil)

### Analiz AkÄ±ÅŸÄ±

```
1. Document Processor
   â†“
   PDF/DOCX â†’ Metin Ã§Ä±karÄ±mÄ±
   â†“
2. LLM Analiz (OpenAI)
   â†“
   - Requirements Extractor (gpt-3.5-turbo)
   - Compliance Analyst (pattern matching + keyword)
   - Proposal Writer (template-based)
   â†“
3. SonuÃ§lar
   - JSON report
   - Markdown summary
   - PDF report
```

## ğŸ“Š DetaylÄ± Analiz SÃ¼reci

### 1. Document Processor (`document_processor.py`)
- PDF'lerden metin Ã§Ä±karÄ±r (`pdfplumber`)
- DOCX'lerden metin Ã§Ä±karÄ±r (`python-docx`)
- Sayfa sayÄ±sÄ±, karakter sayÄ±sÄ± hesaplar

### 2. LLM Analyzer (`llm_analyzer.py`)
- **Model**: `gpt-3.5-turbo` (OpenAI)
- **API Key**: `OPENAI_API_KEY` environment variable'dan alÄ±nÄ±yor
- **Fonksiyonlar**:
  - `extract_requirements()`: Gereksinim Ã§Ä±karÄ±mÄ±
  - `analyze_document_by_type()`: Belge tipine gÃ¶re analiz
  - `analyze_document_by_criteria()`: Kriter bazlÄ± analiz

### 3. Opportunity Pipeline (`mergenlite_opportunity_pipeline.py`)
- **AutoGen Agents** (eÄŸer AutoGen yÃ¼klÃ¼yse):
  - Requirements Agent
  - Compliance Agent
  - Commercial Agent
  - Reporter Agent
- **LLM Config**: `get_llm_config()` â†’ OpenAI kullanÄ±yor
- **Mock Mode**: EÄŸer AutoGen veya OpenAI API key yoksa mock analiz yapÄ±yor

## âš™ï¸ Ollama DesteÄŸi

### Mevcut Durum
- Ollama **ÅŸu anda kullanÄ±lmÄ±yor**
- Eski dosyalarda Ollama referanslarÄ± var:
  - `mergenlite_agents.py` â†’ `USE_OLLAMA` environment variable kontrolÃ¼
  - `mergen/sam/document_management/autogen_agents.py` â†’ Ollama desteÄŸi var

### Ollama'yÄ± Aktif Etmek Ä°Ã§in

1. **Ollama'yÄ± baÅŸlat**:
   ```bash
   ollama serve
   ```

2. **Model yÃ¼kle**:
   ```bash
   ollama pull llama3.2
   ```

3. **Environment variable ekle**:
   ```env
   USE_OLLAMA=true
   OLLAMA_URL=http://localhost:11434
   OLLAMA_MODEL=llama3.2
   ```

4. **Kod gÃ¼ncellemesi gerekli**:
   - `mergenlite_opportunity_pipeline.py` â†’ `get_llm_config()` fonksiyonunu gÃ¼ncelle
   - `llm_analyzer.py` â†’ Ollama desteÄŸi ekle

## ğŸ”§ Åu Anki Analiz YÃ¶ntemi

### OpenAI KullanÄ±mÄ±
```python
# mergenlite_opportunity_pipeline.py
def get_llm_config():
    api_key = os.getenv("OPENAI_API_KEY", "")
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    
    if not api_key:
        return None  # Mock mode
    
    return {
        "config_list": [{
            "model": model,
            "api_key": api_key
        }],
        "temperature": 0.1,
        "timeout": 120
    }
```

### LLM Analyzer
```python
# llm_analyzer.py
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[...],
    temperature=0.2,
    max_tokens=2000
)
```

## ğŸ“ SonuÃ§

- **Ollama**: âŒ KullanÄ±lmÄ±yor (process Ã§alÄ±ÅŸmÄ±yor)
- **OpenAI**: âœ… KullanÄ±lÄ±yor (eÄŸer API key varsa)
- **Mock Mode**: âœ… Fallback olarak kullanÄ±lÄ±yor (API key yoksa)

## ğŸš€ Ollama'yÄ± Aktif Etmek Ä°sterseniz

1. Ollama'yÄ± baÅŸlatÄ±n
2. Model yÃ¼kleyin
3. `mergenlite_opportunity_pipeline.py` ve `llm_analyzer.py` dosyalarÄ±nÄ± gÃ¼ncelleyin
4. Environment variable'larÄ± ayarlayÄ±n

