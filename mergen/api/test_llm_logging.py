#!/usr/bin/env python3
"""Test LLM logging with new analysis."""
import requests
import time
import sys
sys.path.insert(0, '/app')

from app.db import SessionLocal
from app.models import LLMCall

API_BASE = "http://localhost:8000"
OPP_ID = 6  # Houston opportunity

print("=" * 70)
print("ğŸ§ª LLM LOGGING TEST - YENÄ° ANALÄ°Z")
print("=" * 70)
print()

# Get initial LLM call count
db = SessionLocal()
initial_count = db.query(LLMCall).count()
db.close()

print(f"ğŸ“Š BaÅŸlangÄ±Ã§ LLM Ã‡aÄŸrÄ± SayÄ±sÄ±: {initial_count}")
print()

# Start new SOW analysis
print("ğŸ“„ Yeni SOW Analysis baÅŸlatÄ±lÄ±yor...")
sow_resp = requests.post(
    f"{API_BASE}/api/pipeline/run",
    json={"opportunity_id": OPP_ID, "analysis_type": "sow_draft"}
)
if sow_resp.status_code == 200:
    sow_result = sow_resp.json()
    sow_analysis_id = sow_result.get("analysis_result_id")
    print(f"   âœ… SOW Analysis ID: {sow_analysis_id}")
    
    # Wait for completion
    print(f"\nâ³ SOW Analysis tamamlanmasÄ± bekleniyor...")
    for i in range(20):  # Max 10 minutes
        time.sleep(30)
        status_resp = requests.get(f"{API_BASE}/api/pipeline/results/{sow_analysis_id}")
        if status_resp.status_code == 200:
            status_data = status_resp.json()
            status = status_data.get('status')
            print(f"   Status: {status} ({i*30}s)")
            
            if status == 'completed':
                print(f"   âœ… SOW Analysis tamamlandÄ±!")
                
                # Check LLM calls
                db = SessionLocal()
                final_count = db.query(LLMCall).count()
                new_calls = db.query(LLMCall).order_by(LLMCall.created_at.desc()).limit(5).all()
                db.close()
                
                print(f"\nğŸ“Š LLM Ã‡aÄŸrÄ± KontrolÃ¼:")
                print(f"   Yeni LLM Ã‡aÄŸrÄ± SayÄ±sÄ±: {final_count - initial_count}")
                print(f"\n   Son 5 LLM Ã‡aÄŸrÄ±sÄ±:")
                for call in new_calls:
                    print(f"      ID: {call.id}")
                    print(f"      Provider: {call.provider}")
                    print(f"      Model: {call.model}")
                    print(f"      Agent: {call.agent_name}")
                    print(f"      Prompt: {'âœ…' if call.prompt else 'âŒ'} ({len(call.prompt) if call.prompt else 0} chars)")
                    print(f"      Response: {'âœ…' if call.response else 'âŒ'} ({len(call.response) if call.response else 0} chars)")
                    print(f"      Tokens: {call.prompt_tokens}/{call.completion_tokens}/{call.total_tokens}")
                    print(f"      Latency: {call.latency_ms}ms")
                    print()
                
                if final_count > initial_count:
                    print("   âœ… LLM Ã§aÄŸrÄ±larÄ± baÅŸarÄ±yla kaydedildi!")
                else:
                    print("   âš ï¸ Yeni LLM Ã§aÄŸrÄ±sÄ± kaydedilmedi")
                
                break
            elif status == 'failed':
                print(f"   âŒ SOW Analysis baÅŸarÄ±sÄ±z!")
                break
else:
    print(f"   âŒ SOW Analysis baÅŸlatÄ±lamadÄ±: {sow_resp.status_code}")

print()
print("=" * 70)

