#!/usr/bin/env python3
"""
MergenAI Lite - Rehberli Analiz ModÃ¼lÃ¼
4 AÅŸamalÄ± Ä°lan Analiz Workflow'u:
1. Metadata ve DokÃ¼man Ä°ndirme
2. DokÃ¼man Ä°ÅŸleme (PDF/DOCX Metin Ã‡Ä±karÄ±mÄ±)
3. RAG Muhakemesi (LLM ile Ã–zellik Ã‡Ä±karÄ±mÄ±)
4. Final Rapor
"""

import streamlit as st
import pandas as pd
from datetime import datetime
from pathlib import Path
import json
import time
import os
import re
import logging
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)

# Local imports
from sam_integration import SAMIntegration
from document_processor import DocumentProcessor
from rag_service import RAGService
from llm_analyzer import LLMAnalyzer

# Proposal generator (opsiyonel)
try:
    from proposal_pipeline import generate_proposal_from_analysis, get_llm_config
    PROPOSAL_GENERATOR_AVAILABLE = True
except ImportError:
    PROPOSAL_GENERATOR_AVAILABLE = False
    logger.warning("Proposal generator not available")

# Orchestrator kullanÄ±lmÄ±yor - direkt analiz yapÄ±lÄ±yor
# Autogen Ã§aÄŸrÄ±larÄ± kaldÄ±rÄ±ldÄ± - basit ve hÄ±zlÄ± analiz pipeline kullanÄ±lÄ±yor

def render_guided_analysis_page(opportunity: Dict[str, Any]):
    """
    Modern AI Analysis Interface - MergenLite Core
    Real-time agent workflow with live progress tracking
    """
    
    # Header with modern gradient
    st.markdown('<h1 class="main-header">ğŸ¤– AI Analiz - CanlÄ± Ajan Ã‡alÄ±ÅŸmasÄ±</h1>', unsafe_allow_html=True)
    
    # SeÃ§ilen ilan bilgisi - Modern card design
    # Label clarity: Show both IDs explicitly
    notice_id = opportunity.get('noticeId') or opportunity.get('solicitationNumber') or 'N/A'
    opportunity_id = opportunity.get('opportunityId') or opportunity.get('opportunity_id', '')
    title = opportunity.get('title', 'BaÅŸlÄ±k Yok')
    
    # SAM.gov view link oluÅŸtur
    sam_gov_link = opportunity.get('samGovLink') or opportunity.get('sam_gov_link')
    if not sam_gov_link:
        if opportunity_id and len(str(opportunity_id)) == 32:  # Opportunity ID (32 karakter hex)
            sam_gov_link = f"https://sam.gov/opp/{opportunity_id}/view"
        elif notice_id and notice_id != 'N/A':
            sam_gov_link = f"https://sam.gov/opportunities/search?noticeId={notice_id}"
    
    sam_link_html = ""
    if sam_gov_link:
        sam_link_html = f'<a href="{sam_gov_link}" target="_blank" style="color: var(--blue-400); text-decoration: none; font-size: 12px; margin-left: 8px; font-weight: 600; display: inline-flex; align-items: center; gap: 4px;">ğŸ”— SAM.gov\'da GÃ¶rÃ¼ntÃ¼le</a>'
    
    st.markdown(f"""
    <div class="op-card" style="margin-bottom: 24px; background: linear-gradient(135deg, rgba(124,58,237,.15), rgba(59,130,246,.1)); border: 1px solid rgba(124,58,237,.3);">
        <div style="display: flex; align-items: center; gap: 16px; margin-bottom: 12px; flex-wrap: wrap;">
            <span style="font-size: 24px;">ğŸ“„</span>
            <div style="flex: 1;">
                <h3 style="color: var(--text); font-size: 18px; font-weight: 600; margin: 0;">{title}</h3>
                <div style="display: flex; align-items: center; gap: 8px; margin-top: 4px; flex-wrap: wrap;">
                    {f'<p style="color: var(--blue-400); font-size: 12px; margin: 0; font-weight: 500;">Opportunity ID: {opportunity_id[:20]}...</p>' if opportunity_id and opportunity_id != 'N/A' else ''}
                    {f'<p style="color: var(--text-400); font-size: 12px; margin: 0;">Notice ID: {notice_id}</p>' if notice_id and notice_id != 'N/A' else ''}
                    {sam_link_html}
                </div>
            </div>
        </div>
        <div style="display: flex; align-items: center; gap: 24px; color: var(--text-400); font-size: 14px;">
            <div style="display: flex; align-items: center; gap: 6px;">
                <span>ğŸ“…</span>
                <span>YanÄ±t: {opportunity.get('responseDeadline', 'BelirtilmemiÅŸ')}</span>
            </div>
            <div style="display: flex; align-items: center; gap: 6px;">
                <span>â±ï¸</span>
                <span>{opportunity.get('daysLeft', 'N/A')} gÃ¼n kaldÄ±</span>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # FÄ±rsat AÃ§Ä±klamasÄ± - SadeleÅŸtirilmiÅŸ (collapsed)
    description = opportunity.get('description') or opportunity.get('descriptionText') or opportunity.get('summary') or ''
    if description:
        with st.expander("ğŸ“ FÄ±rsat AÃ§Ä±klamasÄ±", expanded=False):
            import re
            clean_description = re.sub(r'<[^>]+>', '', str(description))
            if len(clean_description) > 2000:
                clean_description = clean_description[:2000] + "..."
            st.markdown(f"<div style='color: var(--text-300); font-size: 14px; line-height: 1.6;'>{clean_description}</div>", unsafe_allow_html=True)
    
    # Analiz GeÃ§miÅŸi BÃ¶lÃ¼mÃ¼ - Bu fÄ±rsat iÃ§in yapÄ±lan analizler
    st.markdown("---")
    st.markdown("### ğŸ“Š Analiz GeÃ§miÅŸi")
    
    # DB'den bu fÄ±rsat iÃ§in analiz geÃ§miÅŸini yÃ¼kle
    analysis_history = []
    try:
        # DB kontrolÃ¼
        try:
            from mergenlite_models import AIAnalysisResult, Opportunity
            from sqlalchemy import create_engine
            from sqlalchemy.orm import sessionmaker
            DB_AVAILABLE = True
        except ImportError:
            DB_AVAILABLE = False
        
        if DB_AVAILABLE:
            from app import get_db_session
            import json
            
            db = get_db_session()
            if db:
                try:
                    # Opportunity'yi bul
                    opp_db = None
                    if opportunity_id and len(str(opportunity_id)) == 32:
                        opp_db = db.query(Opportunity).filter(Opportunity.opportunity_id == opportunity_id).first()
                    elif notice_id and notice_id != 'N/A':
                        opp_db = db.query(Opportunity).filter(Opportunity.notice_id == notice_id).first()
                    
                    if opp_db:
                        # Bu opportunity iÃ§in analizleri bul
                        analyses = db.query(AIAnalysisResult).filter(
                            AIAnalysisResult.opportunity_id == opp_db.opportunity_id
                        ).order_by(AIAnalysisResult.timestamp.desc()).limit(10).all()
                        
                        for analysis in analyses:
                            result_data = analysis.result or {}
                            if isinstance(result_data, str):
                                try:
                                    result_data = json.loads(result_data)
                                except:
                                    result_data = {}
                            
                            # Skor hesapla
                            skor = "N/A"
                            skor_class = "badge-info"
                            if result_data:
                                score = result_data.get('data', {}).get('proposal', {}).get('overall_score') or \
                                        result_data.get('compliance', {}).get('score') or \
                                        (float(analysis.confidence) * 100 if analysis.confidence else None)
                                if score:
                                    if score >= 80:
                                        skor = "MÃ¼kemmel"
                                        skor_class = "badge-success"
                                    elif score >= 60:
                                        skor = "Ä°yi"
                                        skor_class = "badge-info"
                                    elif score >= 40:
                                        skor = "Orta"
                                        skor_class = "badge-warning"
                                    else:
                                        skor = "DÃ¼ÅŸÃ¼k"
                                        skor_class = "badge-danger"
                            
                            # Durum
                            status_map = {
                                'COMPLETED': 'TamamlandÄ±',
                                'IN_PROGRESS': 'Devam Ediyor',
                                'FAILED': 'BaÅŸarÄ±sÄ±z',
                                'PENDING': 'Beklemede'
                            }
                            status = status_map.get(analysis.analysis_type, analysis.analysis_type)
                            
                            analysis_history.append({
                                'id': analysis.id,
                                'opportunity_id': analysis.opportunity_id,
                                'status': status,
                                'skor': skor,
                                'skor_class': skor_class,
                                'timestamp': analysis.timestamp.strftime("%Y-%m-%d %H:%M") if analysis.timestamp else "N/A",
                                'result_data': result_data
                            })
                finally:
                    db.close()
    except Exception as e:
        logger.error(f"Analiz geÃ§miÅŸi yÃ¼kleme hatasÄ±: {e}", exc_info=True)
    
    # Analiz geÃ§miÅŸi listesi
    if analysis_history:
        for analysis in analysis_history:
            col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
            with col1:
                st.markdown(f"""
                <div class="modern-card" style="margin-bottom: 10px; padding: 14px;">
                    <div style="display: flex; align-items: center; gap: 12px;">
                        <span style="color: var(--text-300); font-size: 14px; font-weight: 500;">Analiz #{analysis['id']}</span>
                        <span class="badge badge-info" style="font-size: 11px;">{analysis['status']}</span>
                        <span class="badge {analysis['skor_class']}" style="font-size: 11px;">{analysis['skor']}</span>
                    </div>
                    <div style="color: var(--text-400); font-size: 12px; margin-top: 4px;">{analysis['timestamp']}</div>
                </div>
                """, unsafe_allow_html=True)
            with col4:
                if st.button("ğŸ“„ Detay", key=f"detail_{analysis['id']}", use_container_width=True):
                    st.session_state.selected_analysis_data = analysis
                    st.session_state.current_page = 'RESULTS'
                    st.rerun()
    else:
        st.info("HenÃ¼z analiz yapÄ±lmamÄ±ÅŸ. AÅŸaÄŸÄ±daki 'Analiz Et' butonuna tÄ±klayarak analiz baÅŸlatabilirsiniz.")
    
    # HÄ±zlÄ± Aksiyonlar BÃ¶lÃ¼mÃ¼ - Fonksiyon OdaklÄ±
    st.markdown("---")
    st.markdown("### ğŸš€ HÄ±zlÄ± Aksiyonlar")
    
    # FÄ±rsat kodu
    opportunity_code = opportunity.get('solicitationNumber') or notice_id or opportunity_id or 'UNKNOWN'
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“ KlasÃ¶r OluÅŸtur ve AÃ§", use_container_width=True, key="create_folder"):
            try:
                import subprocess
                import platform
                
                folder = Path(".") / "opportunities" / opportunity_code
                folder.mkdir(parents=True, exist_ok=True)
                folder_path = str(folder.absolute())
                
                if platform.system() == "Windows":
                    subprocess.Popen(f'explorer "{folder_path}"')
                elif platform.system() == "Darwin":
                    subprocess.Popen(["open", folder_path])
                else:
                    subprocess.Popen(["xdg-open", folder_path])
                
                st.success(f"âœ… KlasÃ¶r oluÅŸturuldu: `{folder_path}`")
                st.info("ğŸ’¡ DÃ¶kÃ¼manlarÄ± bu klasÃ¶re kaydedin, sonra 'Analiz Et' butonuna tÄ±klayÄ±n.")
            except Exception as e:
                st.error(f"âŒ KlasÃ¶r oluÅŸturma hatasÄ±: {str(e)}")
    
    with col2:
        if st.button("ğŸ“¤ DÃ¶kÃ¼man YÃ¼kle", use_container_width=True, key="upload_docs"):
            st.session_state['show_upload'] = True
            st.rerun()
    
    with col3:
        if st.button("â–¶ Analiz Et", use_container_width=True, type="primary", key="analyze_btn"):
            if not st.session_state.ai_analysis_state.get('analysis_running', False):
                start_ai_analysis(opportunity)
            else:
                st.warning("âš ï¸ Analiz zaten devam ediyor...")
    
    # DÃ¶kÃ¼man YÃ¼kleme BÃ¶lÃ¼mÃ¼
    if st.session_state.get('show_upload', False):
        st.markdown("---")
        st.markdown("#### ğŸ“¤ DÃ¶kÃ¼man YÃ¼kleme")
        
        folder = Path(".") / "opportunities" / opportunity_code
        folder.mkdir(parents=True, exist_ok=True)
        
        # Mevcut dosyalar
        existing_files = []
        if folder.exists():
            existing_files = (
                list(folder.glob("*.pdf")) + 
                list(folder.glob("*.docx")) + 
                list(folder.glob("*.txt")) +
                list(folder.glob("*.zip")) +
                list(folder.glob("*.xls")) +
                list(folder.glob("*.xlsx"))
            )
            existing_files = [f for f in existing_files if f.name != 'analysis_report.pdf']
        
        if existing_files:
            st.markdown("**ğŸ“ KlasÃ¶rdeki Mevcut DÃ¶kÃ¼manlar:**")
            for f in existing_files[:5]:
                st.markdown(f"  - `{f.name}` ({f.stat().st_size / 1024:.1f} KB)")
            if len(existing_files) > 5:
                st.markdown(f"  - ... ve {len(existing_files) - 5} dosya daha")
        
        uploaded_files = st.file_uploader(
            "Yeni dÃ¶kÃ¼manlarÄ± seÃ§in (PDF, DOCX, TXT, ZIP, XLS, XLSX)",
            type=['pdf', 'docx', 'doc', 'txt', 'zip', 'xls', 'xlsx'],
            accept_multiple_files=True,
            key="file_uploader_main"
        )
        
        if uploaded_files:
            uploaded_count = 0
            for uploaded_file in uploaded_files:
                try:
                    file_path = folder / uploaded_file.name
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    if uploaded_file.name.lower().endswith('.zip'):
                        from opportunity_runner import extract_zip_to_folder
                        extract_zip_to_folder(file_path, folder)
                    
                    st.success(f"âœ… {uploaded_file.name} yÃ¼klendi")
                    uploaded_count += 1
                except Exception as e:
                    st.error(f"âŒ {uploaded_file.name} yÃ¼klenirken hata: {str(e)}")
            
            if uploaded_count > 0:
                st.success(f"ğŸ‰ {uploaded_count} dÃ¶kÃ¼man baÅŸarÄ±yla yÃ¼klendi!")
                st.session_state['show_upload'] = False
                st.rerun()
    
    # Form-Based Analysis Configuration - Collapsed
    with st.expander("âš™ï¸ Analiz KonfigÃ¼rasyonu (Form TabanlÄ±)", expanded=False):
        col_form1, col_form2 = st.columns(2)
        
        with col_form1:
            company_name = st.text_input("ğŸ¢ Firma AdÄ±", value="", key="form_company_name", help="Analiz edilecek firma adÄ±")
            project_type = st.text_input("ğŸ“‹ Proje Tipi", value="", key="form_project_type", help="Ã–rn: Conference and Lodging Support")
            location = st.text_input("ğŸ“ Konum", value="", key="form_location", help="Etkinlik yeri (ÅŸehir/Ã¼lke)")
            dates = st.text_input("ğŸ“… Tarih AralÄ±ÄŸÄ±", value="", key="form_dates", help="Ã–rn: April 14-18, 2024")
            participants = st.number_input("ğŸ‘¥ KatÄ±lÄ±mcÄ± SayÄ±sÄ±", min_value=1, value=1, key="form_participants", help="Tahmini katÄ±lÄ±mcÄ± sayÄ±sÄ±")
        
        with col_form2:
            budget = st.number_input("ğŸ’° Tahmini BÃ¼tÃ§e ($)", min_value=0, value=0, key="form_budget", help="Tahmini bÃ¼tÃ§e miktarÄ±")
            naics_code = st.text_input("ğŸ”¢ NAICS Kodu", value=opportunity.get('naicsCode', '721110'), key="form_naics", help="NAICS kodu")
            contract_type = st.selectbox("ğŸ“„ SÃ¶zleÅŸme TÃ¼rÃ¼", ["Fixed Price", "Time & Materials", "Cost Plus", "IDIQ", "DiÄŸer"], key="form_contract_type")
            evaluation_focus = st.multiselect(
                "ğŸ¯ Analiz Kriterleri (Ã–ncelikli)",
                [
                    "Room capacity and ADA compliance",
                    "Conference space AV requirements",
                    "FAR/DFAR compliance clauses",
                    "Electronic invoicing (IPP)",
                    "Small business eligibility",
                    "Lojistik",
                    "Uyumluluk (Compliance)",
                    "Maliyet",
                    "AV Gereksinimleri",
                    "Performans ReferanslarÄ±"
                ],
                key="form_evaluation_focus",
                help="PDF analizinde Ã¶ncelik verilecek kriterler"
            )
    
    # Form verilerini session state'e kaydet
    form_data = {
        "company_name": company_name,
        "project_type": project_type,
        "location": location,
        "dates": dates,
        "participants": participants,
        "budget": budget,
        "naics": naics_code,
        "contract_type": contract_type,
        "evaluation_focus": evaluation_focus
    }
    st.session_state.form_data = form_data
    
    # Initialize analysis state
    if 'ai_analysis_state' not in st.session_state:
        st.session_state.ai_analysis_state = {
            'current_stage': 0,
            'completed_stages': [],
            'analysis_running': False,
            'results': None,
            'start_time': None
        }
    
    # Initialize legacy analysis data
    if 'analysis_data' not in st.session_state:
        st.session_state.analysis_data = {}
    
    if 'analysis_stage' not in st.session_state:
        st.session_state.analysis_stage = 1
    
    # Otomatik vendor profile yÃ¼kleme - Sayfa yÃ¼klendiÄŸinde (widget'lardan Ã–NCE)
    # EÄŸer vendor bilgileri yoksa ve PDF mevcutsa otomatik yÃ¼kle
    if 'vendor_profile_auto_loaded' not in st.session_state:
        try:
            samples_pdf = Path("samples") / "CREATA_GLOBAL_MEETING_AND_EVENTS_PAST_PERFORMANCE_copy[1].pdf"
            if samples_pdf.exists():
                # Vendor bilgileri yoksa veya boÅŸsa otomatik yÃ¼kle
                if not st.session_state.get('vendor_company_name') or not st.session_state.get('vendor_uei'):
                    with st.spinner("ğŸ“„ Åirket bilgileri PDF'den otomatik yÃ¼kleniyor..."):
                        from vendor_profile_extractor import extract_vendor_profile_from_pdf
                        
                        vendor_profile = extract_vendor_profile_from_pdf(str(samples_pdf))
                        
                        # Session state'e kaydet (widget'lardan Ã¶nce)
                        st.session_state['vendor_company_name'] = vendor_profile.get('company_name', '')
                        st.session_state['vendor_address'] = vendor_profile.get('address', '')
                        st.session_state['vendor_uei'] = vendor_profile.get('uei', '')
                        st.session_state['vendor_duns'] = vendor_profile.get('duns', '')
                        st.session_state['vendor_sam_registered'] = vendor_profile.get('sam_registered', True)
                        st.session_state['vendor_contact_name'] = vendor_profile.get('contact', {}).get('name', '')
                        st.session_state['vendor_contact_email'] = vendor_profile.get('contact', {}).get('email', '')
                        st.session_state['vendor_contact_phone'] = vendor_profile.get('contact', {}).get('phone', '')
                        st.session_state['vendor_past_performance'] = '\n'.join(vendor_profile.get('past_performance', []))
                        
                        # Flag set et - bir daha yÃ¼kleme
                        st.session_state['vendor_profile_auto_loaded'] = True
                        
                        logger.info(f"[Vendor Profile] Auto-loaded from PDF: {vendor_profile.get('company_name', 'N/A')}")
        except Exception as e:
            logger.warning(f"[Vendor Profile] Auto-load failed: {e}", exc_info=True)
            # Hata olsa bile flag set et, sÃ¼rekli deneme yapmasÄ±n
            st.session_state['vendor_profile_auto_loaded'] = True
    
    # Analiz Durumu - Sadece Ã§alÄ±ÅŸÄ±yorsa gÃ¶ster
    if st.session_state.ai_analysis_state.get('analysis_running', False):
        st.markdown("---")
        st.markdown("### ğŸ“Š Analiz Durumu")
        
        # Progress bar
        total_stages = 4
        completed_stages = len(st.session_state.ai_analysis_state.get('completed_stages', []))
        progress = completed_stages / total_stages if total_stages > 0 else 0
        
        st.progress(progress)
        st.caption(f"Ä°lerleme: {completed_stages}/{total_stages} aÅŸama tamamlandÄ±")
        
        # Stage indicator - Kompakt
        stages = [
            ("ğŸ“„", "DÃ¶kÃ¼man Ä°ÅŸleme"),
            ("ğŸ›¡ï¸", "Uyumluluk"),
            ("ğŸ”", "Gereksinimler"),
            ("âœï¸", "Rapor")
        ]
        
        current_stage = st.session_state.ai_analysis_state.get('current_stage', 0)
        completed = st.session_state.ai_analysis_state.get('completed_stages', [])
        
        cols = st.columns(4)
        for i, (icon, name) in enumerate(stages):
            with cols[i]:
                if i in completed:
                    st.markdown(f"<div style='text-align: center; padding: 12px; background: rgba(16,185,129,.1); border-radius: 8px; border: 1px solid rgba(16,185,129,.3);'><div style='font-size: 24px;'>{icon}</div><div style='font-size: 11px; color: var(--text-300); margin-top: 4px;'>âœ… {name}</div></div>", unsafe_allow_html=True)
                elif i == current_stage:
                    st.markdown(f"<div style='text-align: center; padding: 12px; background: rgba(245,158,11,.1); border-radius: 8px; border: 1px solid rgba(245,158,11,.3);'><div style='font-size: 24px;'>ğŸ”„</div><div style='font-size: 11px; color: var(--text-300); margin-top: 4px;'>{name}</div></div>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<div style='text-align: center; padding: 12px; background: rgba(17,24,39,.3); border-radius: 8px; border: 1px solid var(--border); opacity: 0.6;'><div style='font-size: 24px;'>{icon}</div><div style='font-size: 11px; color: var(--text-400); margin-top: 4px;'>{name}</div></div>", unsafe_allow_html=True)
        
        # Stop button
        if st.button("â¹ï¸ Analizi Durdur", use_container_width=True, key="stop_analysis_main"):
            stop_ai_analysis()
    
    # SonuÃ§lar - TamamlandÄ±ysa gÃ¶ster
    if st.session_state.ai_analysis_state.get('results') and not st.session_state.ai_analysis_state.get('analysis_running', False):
        st.markdown("---")
        st.markdown("### âœ… Analiz TamamlandÄ±")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("ğŸ“Š DetaylÄ± SonuÃ§larÄ± GÃ¶r", use_container_width=True, key="view_detailed_results"):
                st.session_state.current_page = 'RESULTS'
                st.session_state.selected_opportunity = opportunity
                st.rerun()
        
        with col2:
            # PDF indirme
            results = st.session_state.ai_analysis_state.get('results', {})
            pdf_path = results.get('metadata', {}).get('report_pdf_path')
            if pdf_path and Path(pdf_path).exists():
                with open(pdf_path, "rb") as pdf_file:
                    st.download_button(
                        label="ğŸ“¥ PDF Raporu Ä°ndir",
                        data=pdf_file,
                        file_name=f"analysis_report_{opportunity_code}.pdf",
                        mime="application/pdf",
                        use_container_width=True,
                        key="download_pdf"
                    )
        
        with col3:
            # Proposal ve SOW oluÅŸturma
            col_prop, col_sow = st.columns(2)
            with col_prop:
                if st.button("ğŸ“ Teklif TaslaÄŸÄ±", use_container_width=True, type="primary", key="generate_proposal"):
                    st.session_state['show_proposal_generator'] = True
                    st.rerun()
            with col_sow:
                if st.button("ğŸ¨ SOW OluÅŸtur", use_container_width=True, type="secondary", key="generate_sow"):
                    st.session_state['show_sow_generator'] = True
                    st.rerun()
        
        # Proposal Generator BÃ¶lÃ¼mÃ¼
        if st.session_state.get('show_proposal_generator', False):
            st.markdown("---")
            st.markdown("### ğŸ“ Teklif TaslaÄŸÄ± OluÅŸtur")
            
            # PDF extraction iÅŸlemlerini widget'lardan Ã–NCE yap (session state gÃ¼ncellemesi iÃ§in)
            # PDF'den otomatik yÃ¼kleme - Session state gÃ¼ncellemesi
            if 'extract_from_pdf_clicked' in st.session_state and st.session_state['extract_from_pdf_clicked']:
                try:
                    with st.spinner("PDF'den bilgiler Ã§Ä±karÄ±lÄ±yor..."):
                        from vendor_profile_extractor import extract_vendor_profile_from_pdf
                        
                        past_perf_pdf = st.session_state.get('past_perf_pdf_data')
                        if past_perf_pdf:
                            # PDF'i geÃ§ici olarak kaydet
                            temp_pdf = Path(".") / "temp_past_perf.pdf"
                            with open(temp_pdf, "wb") as f:
                                f.write(past_perf_pdf.getbuffer())
                            
                            # Bilgileri Ã§Ä±kar
                            vendor_profile = extract_vendor_profile_from_pdf(str(temp_pdf))
                            
                            # Session state'e kaydet (widget'lardan Ã¶nce)
                            st.session_state['vendor_company_name'] = vendor_profile.get('company_name', '')
                            st.session_state['vendor_address'] = vendor_profile.get('address', '')
                            st.session_state['vendor_uei'] = vendor_profile.get('uei', '')
                            st.session_state['vendor_duns'] = vendor_profile.get('duns', '')
                            st.session_state['vendor_sam_registered'] = vendor_profile.get('sam_registered', True)
                            st.session_state['vendor_contact_name'] = vendor_profile.get('contact', {}).get('name', '')
                            st.session_state['vendor_contact_email'] = vendor_profile.get('contact', {}).get('email', '')
                            st.session_state['vendor_contact_phone'] = vendor_profile.get('contact', {}).get('phone', '')
                            st.session_state['vendor_past_performance'] = '\n'.join(vendor_profile.get('past_performance', []))
                            
                            # GeÃ§ici dosyayÄ± sil
                            temp_pdf.unlink()
                            
                            # Flag'i temizle
                            st.session_state['extract_from_pdf_clicked'] = False
                            st.session_state['past_perf_pdf_data'] = None
                            
                            st.success("âœ… Bilgiler PDF'den baÅŸarÄ±yla Ã§Ä±karÄ±ldÄ±!")
                            st.rerun()
                except Exception as e:
                    logger.error(f"PDF extraction error: {e}", exc_info=True)
                    st.error(f"âŒ PDF'den bilgi Ã§Ä±karma hatasÄ±: {str(e)}")
                    st.session_state['extract_from_pdf_clicked'] = False
            
            # Samples klasÃ¶rÃ¼nden otomatik yÃ¼kle - Session state gÃ¼ncellemesi
            if 'load_from_samples_clicked' in st.session_state and st.session_state['load_from_samples_clicked']:
                try:
                    with st.spinner("PDF'den bilgiler Ã§Ä±karÄ±lÄ±yor..."):
                        from vendor_profile_extractor import extract_vendor_profile_from_pdf
                        
                        samples_pdf = Path("samples") / "CREATA_GLOBAL_MEETING_AND_EVENTS_PAST_PERFORMANCE_copy[1].pdf"
                        if samples_pdf.exists():
                            vendor_profile = extract_vendor_profile_from_pdf(str(samples_pdf))
                            
                            # Session state'e kaydet (widget'lardan Ã¶nce)
                            st.session_state['vendor_company_name'] = vendor_profile.get('company_name', '')
                            st.session_state['vendor_address'] = vendor_profile.get('address', '')
                            st.session_state['vendor_uei'] = vendor_profile.get('uei', '')
                            st.session_state['vendor_duns'] = vendor_profile.get('duns', '')
                            st.session_state['vendor_sam_registered'] = vendor_profile.get('sam_registered', True)
                            st.session_state['vendor_contact_name'] = vendor_profile.get('contact', {}).get('name', '')
                            st.session_state['vendor_contact_email'] = vendor_profile.get('contact', {}).get('email', '')
                            st.session_state['vendor_contact_phone'] = vendor_profile.get('contact', {}).get('phone', '')
                            st.session_state['vendor_past_performance'] = '\n'.join(vendor_profile.get('past_performance', []))
                            
                            # Flag'i temizle
                            st.session_state['load_from_samples_clicked'] = False
                            
                            st.success("âœ… Bilgiler PDF'den baÅŸarÄ±yla Ã§Ä±karÄ±ldÄ±!")
                            st.rerun()
                except Exception as e:
                    logger.error(f"PDF extraction error: {e}", exc_info=True)
                    st.error(f"âŒ PDF'den bilgi Ã§Ä±karma hatasÄ±: {str(e)}")
                    st.session_state['load_from_samples_clicked'] = False
            
            # PDF'den otomatik yÃ¼kleme UI
            col_auto, col_manual = st.columns([1, 1])
            
            with col_auto:
                st.markdown("#### ğŸ“„ PDF'den Otomatik YÃ¼kle")
                past_perf_pdf = st.file_uploader(
                    "Past Performance PDF'i seÃ§in",
                    type=['pdf'],
                    key="past_perf_pdf_upload",
                    help="CREATA_GLOBAL_MEETING_AND_EVENTS_PAST_PERFORMANCE_copy[1].pdf gibi"
                )
                
                if past_perf_pdf:
                    if st.button("ğŸ“¥ PDF'den Bilgileri Ã‡Ä±kar", use_container_width=True, key="extract_from_pdf"):
                        # Flag set et ve PDF'i kaydet
                        st.session_state['extract_from_pdf_clicked'] = True
                        st.session_state['past_perf_pdf_data'] = past_perf_pdf
                        st.rerun()
                
                # Samples klasÃ¶rÃ¼nden otomatik yÃ¼kle
                samples_pdf = Path("samples") / "CREATA_GLOBAL_MEETING_AND_EVENTS_PAST_PERFORMANCE_copy[1].pdf"
                if samples_pdf.exists():
                    if st.button("ğŸ“„ Samples KlasÃ¶rÃ¼nden YÃ¼kle", use_container_width=True, key="load_from_samples"):
                        # Flag set et
                        st.session_state['load_from_samples_clicked'] = True
                        st.rerun()
            
            with col_manual:
                st.markdown("#### âœï¸ Manuel GiriÅŸ")
                st.info("ğŸ’¡ PDF'den otomatik yÃ¼kleme yapabilir veya manuel olarak girebilirsiniz.")
            
            # Vendor Profile Input
            with st.expander("ğŸ¢ Åirket Bilgileri (Vendor Profile)", expanded=True):
                # Otomatik yÃ¼klendi bilgisi gÃ¶ster
                if st.session_state.get('vendor_profile_auto_loaded'):
                    st.info("âœ… Åirket bilgileri CREATA GLOBAL MEETING AND EVENTS PDF'inden otomatik yÃ¼klendi. Gerekirse dÃ¼zenleyebilirsiniz.")
                
                col_v1, col_v2 = st.columns(2)
                
                with col_v1:
                    vendor_company_name = st.text_input("Åirket AdÄ±", value=st.session_state.get('vendor_company_name', ''), key="vendor_company_name")
                    vendor_address = st.text_area("Adres", value=st.session_state.get('vendor_address', ''), key="vendor_address")
                    vendor_uei = st.text_input("UEI", value=st.session_state.get('vendor_uei', ''), key="vendor_uei")
                    vendor_duns = st.text_input("DUNS", value=st.session_state.get('vendor_duns', ''), key="vendor_duns")
                
                with col_v2:
                    vendor_contact_name = st.text_input("Ä°letiÅŸim KiÅŸisi", value=st.session_state.get('vendor_contact_name', ''), key="vendor_contact_name")
                    vendor_contact_email = st.text_input("E-posta", value=st.session_state.get('vendor_contact_email', ''), key="vendor_contact_email")
                    vendor_contact_phone = st.text_input("Telefon", value=st.session_state.get('vendor_contact_phone', ''), key="vendor_contact_phone")
                    vendor_sam_registered = st.checkbox("SAM.gov'da KayÄ±tlÄ±", value=st.session_state.get('vendor_sam_registered', True), key="vendor_sam_registered")
                
                # Past Performance
                st.markdown("**GeÃ§miÅŸ Performans (Past Performance):**")
                past_performance_text = st.text_area(
                    "GeÃ§miÅŸ projeleri listeleyin (her satÄ±r bir proje)",
                    value=st.session_state.get('vendor_past_performance', ''),
                    key="vendor_past_performance",
                    help="Ã–rn: Event X - 300 participants - Department of Interior"
                )
                past_performance = [line.strip() for line in past_performance_text.split('\n') if line.strip()]
            
            # Vendor profile oluÅŸtur
            vendor_profile = {
                "company_name": vendor_company_name,
                "address": vendor_address,
                "uei": vendor_uei,
                "duns": vendor_duns,
                "sam_registered": vendor_sam_registered,
                "contact": {
                    "name": vendor_contact_name,
                    "email": vendor_contact_email,
                    "phone": vendor_contact_phone
                },
                "past_performance": past_performance
            }
            
            # Session state'e kaydet
            for key, value in vendor_profile.items():
                if key != 'contact' and key != 'past_performance':
                    st.session_state[f'vendor_{key}'] = value
                elif key == 'contact':
                    for ckey, cvalue in value.items():
                        st.session_state[f'vendor_contact_{ckey}'] = cvalue
                elif key == 'past_performance':
                    st.session_state['vendor_past_performance'] = past_performance_text
            
            # Proposal oluÅŸtur butonu
            if st.button("ğŸš€ Teklif TaslaÄŸÄ±nÄ± OluÅŸtur", use_container_width=True, type="primary", key="create_proposal"):
                if not vendor_company_name:
                    st.error("âŒ LÃ¼tfen ÅŸirket adÄ±nÄ± girin.")
                else:
                    try:
                        folder_path = Path(".") / "opportunities" / opportunity_code
                        
                        with st.spinner("ğŸ“ Teklif taslaÄŸÄ± oluÅŸturuluyor..."):
                            from proposal_pipeline import generate_proposal_from_analysis, get_llm_config
                            
                            llm_config = get_llm_config()
                            proposal_path = generate_proposal_from_analysis(
                                folder_path=str(folder_path),
                                vendor_profile=vendor_profile,
                                llm_config=llm_config
                            )
                            
                            st.success(f"âœ… Teklif taslaÄŸÄ± oluÅŸturuldu: `{proposal_path}`")
                            st.session_state['proposal_path'] = proposal_path
                            st.session_state['proposal_generated'] = True
                            st.rerun()
                    except Exception as e:
                        logger.error(f"Proposal generation error: {e}", exc_info=True)
                        st.error(f"âŒ Teklif oluÅŸturma hatasÄ±: {str(e)}")
            
            # OluÅŸturulan proposal'Ä± gÃ¶ster
            proposal_path = st.session_state.get('proposal_path')
            if proposal_path and Path(proposal_path).exists():
                st.markdown("---")
                st.markdown("### ğŸ“„ OluÅŸturulan Teklif TaslaÄŸÄ±")
                
                with open(proposal_path, 'r', encoding='utf-8') as f:
                    proposal_content = f.read()
                
                # Proposal Ã¶nizleme
                st.markdown(proposal_content)
                
                # Ä°ndirme butonlarÄ±
                col_d1, col_d2 = st.columns(2)
                with col_d1:
                    st.download_button(
                        label="ğŸ“¥ Markdown Ä°ndir",
                        data=proposal_content,
                        file_name=f"proposal_{opportunity_code}.md",
                        mime="text/markdown",
                        use_container_width=True,
                        key="download_proposal_md"
                    )
                
                with col_d2:
                    # PDF'e Ã§evir (opsiyonel)
                    if st.button("ğŸ“„ PDF'e Ã‡evir", use_container_width=True, key="convert_to_pdf"):
                        st.info("ğŸ’¡ PDF dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yakÄ±nda eklenecek. Åimdilik Markdown formatÄ±nÄ± kullanabilirsiniz.")
        
        # SOW Generator BÃ¶lÃ¼mÃ¼
        if st.session_state.get('show_sow_generator', False):
            st.markdown("---")
            st.markdown("### ğŸ¨ Statement of Work (SOW) OluÅŸtur")
            st.info("ğŸ’¡ RFQ analizinden otellere gÃ¶nderilecek profesyonel SOW oluÅŸturulacak. Sample SOW formatÄ± kullanÄ±lacak.")
            
            # Vendor profile bilgileri (varsa)
            vendor_company_name = st.session_state.get('vendor_company_name', '')
            vendor_address = st.session_state.get('vendor_address', '')
            vendor_uei = st.session_state.get('vendor_uei', '')
            vendor_duns = st.session_state.get('vendor_duns', '')
            vendor_sam_registered = st.session_state.get('vendor_sam_registered', True)
            vendor_contact_name = st.session_state.get('vendor_contact_name', '')
            vendor_contact_email = st.session_state.get('vendor_contact_email', '')
            vendor_contact_phone = st.session_state.get('vendor_contact_phone', '')
            
            # SOW oluÅŸtur butonu
            if st.button("ğŸš€ SOW OluÅŸtur", use_container_width=True, type="primary", key="create_sow"):
                try:
                    folder_path = Path(".") / "opportunities" / opportunity_code
                    
                    with st.spinner("ğŸ¨ SOW oluÅŸturuluyor (Sample SOW formatÄ±na gÃ¶re)..."):
                        from sow_generator import generate_sow_from_rfq_analysis
                        
                        # RFQ analiz sonuÃ§larÄ±nÄ± yÃ¼kle
                        report_path = folder_path / "report.json"
                        if not report_path.exists():
                            st.error("âŒ Ã–nce AI analizi yapmalÄ±sÄ±nÄ±z!")
                        else:
                            with open(report_path, 'r', encoding='utf-8') as f:
                                rfq_analysis = json.load(f)
                            
                            # Vendor profile (varsa)
                            vendor_profile = None
                            if vendor_company_name:
                                vendor_profile = {
                                    "company_name": vendor_company_name,
                                    "address": vendor_address,
                                    "uei": vendor_uei,
                                    "duns": vendor_duns,
                                    "sam_registered": vendor_sam_registered,
                                    "contact": {
                                        "name": vendor_contact_name,
                                        "email": vendor_contact_email,
                                        "phone": vendor_contact_phone
                                    }
                                }
                            
                            # Opportunity info
                            opportunity_info = {
                                "solicitation_number": opportunity_code,
                                "title": rfq_analysis.get('opportunity_info', {}).get('title', ''),
                                "agency": rfq_analysis.get('opportunity_info', {}).get('agency', '')
                            }
                            
                            # SOW oluÅŸtur
                            sow_result = generate_sow_from_rfq_analysis(
                                rfq_analysis=rfq_analysis,
                                opportunity_info=opportunity_info,
                                vendor_profile=vendor_profile,
                                output_folder=str(folder_path)
                            )
                            
                            sow_text = sow_result.get('markdown', '')
                            sow_md_path = sow_result.get('markdown_path')
                            sow_pdf_path = sow_result.get('pdf_path')
                            
                            if sow_md_path:
                                st.success(f"âœ… SOW oluÅŸturuldu: `{sow_md_path}`")
                                if sow_pdf_path:
                                    st.success(f"âœ… PDF oluÅŸturuldu: `{sow_pdf_path}`")
                                
                                st.session_state['sow_path'] = sow_md_path
                                st.session_state['sow_pdf_path'] = sow_pdf_path
                                st.session_state['sow_generated'] = True
                                st.rerun()
                            else:
                                st.error("âŒ SOW oluÅŸturulamadÄ±!")
                except Exception as e:
                    logger.error(f"SOW generation error: {e}", exc_info=True)
                    st.error(f"âŒ SOW oluÅŸturma hatasÄ±: {str(e)}")
            
            # OluÅŸturulan SOW'u gÃ¶ster
            sow_path = st.session_state.get('sow_path')
            if sow_path and Path(sow_path).exists():
                st.markdown("---")
                st.markdown("### ğŸ“„ OluÅŸturulan SOW")
                
                with open(sow_path, 'r', encoding='utf-8') as f:
                    sow_content = f.read()
                
                # SOW Ã¶nizleme
                st.markdown(sow_content)
                
                # Ä°ndirme butonlarÄ±
                col_s1, col_s2 = st.columns(2)
                with col_s1:
                    st.download_button(
                        label="ğŸ“¥ Markdown Ä°ndir",
                        data=sow_content,
                        file_name=f"sow_{opportunity_code}.md",
                        mime="text/markdown",
                        use_container_width=True,
                        key="download_sow_md"
                    )
                with col_s2:
                    # PDF dosyasÄ± varsa indir
                    sow_pdf_path = st.session_state.get('sow_pdf_path')
                    if sow_pdf_path and Path(sow_pdf_path).exists():
                        with open(sow_pdf_path, 'rb') as f:
                            pdf_data = f.read()
                        st.download_button(
                            label="ğŸ“¥ PDF Ä°ndir",
                            data=pdf_data,
                            file_name=f"sow_{opportunity_code}.pdf",
                            mime="application/pdf",
                            use_container_width=True,
                            key="download_sow_pdf"
                        )
                    else:
                        st.info("ğŸ’¡ PDF oluÅŸturuluyor...")
    
    # Live Progress Section
    # Results Preview
    if st.session_state.ai_analysis_state['results']:
        render_results_preview(st.session_state.ai_analysis_state['results'])
        
        # Mail gÃ¶nderme bÃ¶lÃ¼mÃ¼ (PDF varsa)
        results_data = st.session_state.ai_analysis_state['results'].get('data', {})
        pdf_path = results_data.get('pdf_path')
        
        if pdf_path and Path(pdf_path).exists():
            st.markdown('<div class="mail-section">', unsafe_allow_html=True)
            st.markdown("### ğŸ“¨ Mail GÃ¶nderimi")
            
            col_email, col_send = st.columns([3, 1])
            
            with col_email:
                target_email = st.text_input(
                    "AlÄ±cÄ± E-posta",
                    value=form_data.get('target_email', '') if form_data else '',
                    key="mail_target_email",
                    help="Raporun gÃ¶nderileceÄŸi e-posta adresi"
                )
            
            with col_send:
                st.markdown("<br>", unsafe_allow_html=True)  # Vertical alignment
                send_mail = st.checkbox(
                    "Bu raporu mail ile gÃ¶ndermeye hazÄ±rÄ±m",
                    key="mail_ready_checkbox"
                )
            
            if send_mail and target_email:
                if st.button("ğŸ“¨ Mail Paketi OluÅŸtur", use_container_width=True, key="create_mail_package"):
                    try:
                        from mail_package import build_mail_package
                        
                        opportunity_code = results_data.get('opportunity_id', 'UNKNOWN')
                        folder_path = Path(pdf_path).parent
                        
                        package = build_mail_package(
                            opportunity_code=opportunity_code,
                            folder_path=str(folder_path),
                            to_email=target_email
                        )
                        
                        st.success("âœ… Mail paketi hazÄ±rlandÄ±!")
                        
                        # Mail Ã¶nizleme
                        with st.expander("ğŸ“§ Mail Ã–nizleme", expanded=True):
                            st.markdown("**Konu:**")
                            st.code(package['subject'])
                            
                            st.markdown("**AlÄ±cÄ±:**")
                            st.code(package['to'])
                            
                            st.markdown("**Ekler:**")
                            for att in package['attachments']:
                                st.code(f"{att['filename']} ({Path(att['path']).stat().st_size / 1024:.1f} KB)")
                            
                            st.markdown("**Mail Ä°Ã§eriÄŸi (HTML):**")
                            st.components.v1.html(package['html_body'], height=400, scrolling=True)
                        
                        # SMTP ayarlarÄ± (opsiyonel)
                        with st.expander("âš™ï¸ SMTP AyarlarÄ± (GÃ¶nderim iÃ§in)", expanded=False):
                            smtp_host = st.text_input("SMTP Host", value="smtp.office365.com", key="smtp_host")
                            smtp_port = st.number_input("SMTP Port", value=587, key="smtp_port")
                            smtp_username = st.text_input("SMTP Username", key="smtp_username")
                            smtp_password = st.text_input("SMTP Password", type="password", key="smtp_password")
                            use_tls = st.checkbox("Use TLS", value=True, key="smtp_tls")
                            
                            if st.button("ğŸ“¤ Mail GÃ¶nder", key="send_email_button"):
                                try:
                                    from mail_package import send_email_via_smtp
                                    
                                    smtp_config = {
                                        'host': smtp_host,
                                        'port': int(smtp_port),
                                        'username': smtp_username,
                                        'password': smtp_password,
                                        'use_tls': use_tls
                                    }
                                    
                                    if send_email_via_smtp(package, smtp_config):
                                        st.success(f"âœ… Mail baÅŸarÄ±yla gÃ¶nderildi: {target_email}")
                                    else:
                                        st.error("âŒ Mail gÃ¶nderilemedi. LÃ¼tfen SMTP ayarlarÄ±nÄ± kontrol edin.")
                                except Exception as e:
                                    st.error(f"âŒ Mail gÃ¶nderme hatasÄ±: {str(e)}")
                        
                        # Package JSON (debug iÃ§in)
                        st.json({
                            "to": package['to'],
                            "subject": package['subject'],
                            "attachments_count": len(package['attachments']),
                            "opportunity_code": package['opportunity_code']
                        })
                        
                    except ImportError:
                        st.warning("âš ï¸ mail_package modÃ¼lÃ¼ bulunamadÄ±")
                    except Exception as e:
                        st.error(f"âŒ Mail paketi oluÅŸturma hatasÄ±: {str(e)}")
                        logger.error(f"Mail package error: {e}", exc_info=True)
            
            st.markdown('</div>', unsafe_allow_html=True)  # Close mail-section

def start_ai_analysis(opportunity: Dict[str, Any]):
    """AI analizini baÅŸlat - Opportunity Runner ile otomatik klasÃ¶r oluÅŸturma ve analiz"""
    try:
        # Opportunity Runner'Ä± import et
        try:
            from opportunity_runner import analyze_opportunity
            USE_OPPORTUNITY_RUNNER = True
        except ImportError:
            USE_OPPORTUNITY_RUNNER = False
            logger.warning("opportunity_runner not available, using legacy method")
        
        # Analiz durumunu gÃ¼ncelle
        st.session_state.ai_analysis_state['analysis_running'] = True
        st.session_state.ai_analysis_state['current_stage'] = 0
        st.session_state.ai_analysis_state['completed_stages'] = []
        st.session_state.ai_analysis_state['start_time'] = datetime.now()
        st.session_state.ai_analysis_state['results'] = None
        
        notice_id = opportunity.get('noticeId') or opportunity.get('solicitationNumber') or opportunity.get('opportunityId', 'N/A')
        opportunity_id = opportunity.get('opportunityId') or opportunity.get('opportunity_id', '')
        
        # FÄ±rsat kodu oluÅŸtur (Notice ID veya Opportunity ID'den)
        opportunity_code = opportunity.get('solicitationNumber') or notice_id or opportunity_id or 'UNKNOWN'
        
        # Form verilerini al
        form_data = st.session_state.get('form_data', {})
        
        # Opportunity Runner kullan (yeni yÃ¶ntem)
        if USE_OPPORTUNITY_RUNNER:
            try:
                logger.info(f"[Opportunity Runner] Starting analysis for: {opportunity_code}")
                
                # Progress container
                progress_container = st.empty()
                status_container = st.empty()
                
                with progress_container.container():
                    st.info("ğŸš€ FÄ±rsat analizi baÅŸlatÄ±lÄ±yor...")
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                
                status_text.text("ğŸ“ KlasÃ¶r oluÅŸturuluyor ve dÃ¶kÃ¼manlar indiriliyor...")
                progress_bar.progress(20)
                
                # Opportunity Runner ile analiz
                # download_from_sam_gov=False: Sadece mevcut klasÃ¶rdeki dÃ¶kÃ¼manlarÄ± kullan (manuel indirme iÃ§in)
                # KullanÄ±cÄ± dÃ¶kÃ¼manlarÄ± manuel olarak klasÃ¶re ekledi, bu yÃ¼zden SAM.gov API'yi kullanmÄ±yoruz
                result = analyze_opportunity(
                    base_dir=".",
                    opportunity_code=opportunity_code,
                    notice_id=notice_id if notice_id != 'N/A' else None,
                    opportunity_id=opportunity_id if opportunity_id and len(opportunity_id) == 32 else None,
                    form_data=form_data,
                    download_from_sam_gov=False  # Sadece mevcut klasÃ¶rdeki dÃ¶kÃ¼manlarÄ± kullan
                )
                
                # Criteria results'Ä± topla (PDF iÃ§in)
                # Bu bilgiyi legacy method'dan alacaÄŸÄ±z, ÅŸimdilik boÅŸ
                criteria_results_for_pdf = {}
                
                progress_bar.progress(100)
                status_text.text("âœ… Analiz tamamlandÄ±!")
                
                # SonuÃ§larÄ± session state'e kaydet
                report_path = Path(result['metadata']['folder']) / 'report.json'
                summary_path = Path(result['metadata']['folder']) / 'summary.md'
                
                # Report ve summary'yi oku
                if report_path.exists():
                    import json
                    with open(report_path, 'r', encoding='utf-8') as f:
                        report_data = json.load(f)
                else:
                    report_data = result.get('report', {})
                
                if summary_path.exists():
                    with open(summary_path, 'r', encoding='utf-8') as f:
                        summary_md = f.read()
                else:
                    summary_md = result.get('summary_md', '')
                
                # PDF path'i al
                pdf_path = result['metadata'].get('report_pdf_path')
                
                # SonuÃ§larÄ± formatla (mevcut format ile uyumlu)
                st.session_state.ai_analysis_state['results'] = {
                    'success': True,
                    'documents_processed': result['metadata'].get('documents_count', 0),
                    'requirements_count': len(report_data.get('event_requirements', {})),
                    'risk_level': report_data.get('fit_assessment', {}).get('overall_score', 0) < 50 and 'high' or 'medium',
                    'duration': result['metadata'].get('analysis_duration_seconds', 0),
                    'data': {
                        'opportunity_id': opportunity_code,
                        'analysis_completed_at': result['metadata'].get('analysis_timestamp', datetime.now().isoformat()),
                        'documents': [],  # Detaylar report'ta
                        'compliance': report_data.get('compliance', {}),
                        'requirements': report_data.get('event_requirements', {}),
                        'proposal': report_data.get('fit_assessment', {}),
                        'form_data': form_data,
                        'report_path': str(report_path),
                        'summary_path': str(summary_path),
                        'summary_md': summary_md,
                        'pdf_path': pdf_path
                    }
                }
                
                st.session_state.ai_analysis_state['analysis_running'] = False
                st.session_state.ai_analysis_state['completed_stages'] = [0, 1, 2, 3]
                
                # VeritabanÄ±na kaydet (Opportunity Runner sonuÃ§larÄ± iÃ§in)
                try:
                    from app import get_db_session
                    from mergenlite_models import AIAnalysisResult
                    
                    db = get_db_session()
                    if db:
                        try:
                            # Overall score hesapla
                            overall_score = report_data.get('fit_assessment', {}).get('overall_score', 0)
                            if isinstance(overall_score, str):
                                try:
                                    overall_score = float(overall_score)
                                except (ValueError, TypeError):
                                    overall_score = 0
                            else:
                                overall_score = float(overall_score or 0)
                            
                            # Confidence hesapla (0-1 arasÄ±)
                            confidence = overall_score / 100.0 if overall_score > 0 else 0.5
                            
                            # AIAnalysisResult kaydet
                            ai_result = AIAnalysisResult(
                                opportunity_id=notice_id if notice_id != 'N/A' else opportunity_code,
                                analysis_type='FULL_ANALYSIS',
                                result=st.session_state.ai_analysis_state['results'],  # Full results
                                confidence=confidence,
                                timestamp=datetime.now(),
                                agent_name='MergenLite Opportunity Runner'
                            )
                            
                            db.add(ai_result)
                            db.commit()
                            
                            logger.info(f"âœ… Analiz sonucu veritabanÄ±na kaydedildi: {ai_result.id}")
                        except Exception as db_error:
                            logger.error(f"âŒ VeritabanÄ± kayÄ±t hatasÄ±: {db_error}", exc_info=True)
                            db.rollback()
                        finally:
                            db.close()
                except Exception as save_error:
                    logger.error(f"âŒ Analiz sonucu kaydetme hatasÄ±: {save_error}", exc_info=True)
                
                with status_container.container():
                    st.success(f"âœ… Analiz tamamlandÄ±! {result['metadata']['documents_count']} dÃ¶kÃ¼man analiz edildi.")
                    
                    # PDF Ã¶nizleme ve indirme
                    if pdf_path and Path(pdf_path).exists():
                        st.markdown("#### ğŸ“„ Analiz Raporu (PDF)")
                        
                        # Ä°ndirme butonu
                        with open(pdf_path, 'rb') as f:
                            pdf_bytes = f.read()
                            st.download_button(
                                label="ğŸ“¥ PDF Raporunu Ä°ndir",
                                data=pdf_bytes,
                                file_name=f"analysis_report_{opportunity_code}.pdf",
                                mime="application/pdf",
                                key="download_pdf_report"
                            )
                        
                        # Inline Ã¶nizleme (Base64 embed)
                        try:
                            import base64
                            b64 = base64.b64encode(pdf_bytes).decode('utf-8')
                            st.markdown(
                                f"""
                                <iframe
                                    src="data:application/pdf;base64,{b64}"
                                    width="100%"
                                    height="600"
                                    style="border:1px solid #ddd; margin-top: 10px;"
                                ></iframe>
                                """,
                                unsafe_allow_html=True
                            )
                        except Exception as e:
                            logger.warning(f"PDF preview failed: {e}")
                            st.info("ğŸ“„ PDF raporu oluÅŸturuldu. YukarÄ±daki butonla indirebilirsiniz.")
                    else:
                        st.warning("âš ï¸ PDF raporu oluÅŸturulamadÄ±. JSON ve Markdown raporlar mevcut.")
                    
                    st.info(f"ğŸ“„ JSON Rapor: {report_path}")
                    st.info(f"ğŸ“ Markdown Ã–zet: {summary_path}")
                
                return
                
            except Exception as e:
                logger.error(f"[ERROR] Opportunity Runner failed: {e}", exc_info=True)
                st.warning(f"âš ï¸ Opportunity Runner hatasÄ±, eski yÃ¶ntem kullanÄ±lÄ±yor: {str(e)}")
                # Fallback to legacy method
                USE_OPPORTUNITY_RUNNER = False
        
        # Legacy method (eski kod devam ediyor)
        if not USE_OPPORTUNITY_RUNNER:
            # Progress container oluÅŸtur
            progress_container = st.empty()
            status_container = st.empty()
        
        with progress_container.container():
            st.info("ğŸš€ Analiz baÅŸlatÄ±lÄ±yor...")
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        start_time = datetime.now()
        processed_documents = []
        requirements_list = []
        compliance_result = {}
        proposal_result = {}
        
        # Stage 1: Document Processor - GerÃ§ek dÃ¶kÃ¼man indirme ve iÅŸleme
        status_text.text("ğŸ“„ Document Processor: PDF/DOCX indirme ve metin Ã§Ä±karÄ±mÄ±...")
        progress_bar.progress(10)
        st.session_state.ai_analysis_state['current_stage'] = 0
        
        try:
            sam = SAMIntegration()
            processor = DocumentProcessor()
            
            # DÃ¶kÃ¼manlarÄ± indir - GeliÅŸtirilmiÅŸ: Hem Opportunity ID hem Notice ID ile dene
            status_text.text(f"ğŸ“¥ DÃ¶kÃ¼manlar indiriliyor: {notice_id}...")
            
            # Ã–nce Notice ID ile dene
            downloaded = sam.download_documents(notice_id, dest_dir="downloads")
            
            # EÄŸer dÃ¶kÃ¼man bulunamazsa ve Opportunity ID formatÄ±ndaysa, Opportunity ID ile de dene
            if not downloaded:
                opportunity_id = opportunity.get('opportunityId') or opportunity.get('opportunity_id', '')
                if opportunity_id and opportunity_id != notice_id and len(opportunity_id) == 32:
                    logger.info(f"ğŸ”„ Notice ID ile dÃ¶kÃ¼man bulunamadÄ±, Opportunity ID ile deniyorum: {opportunity_id}")
                    status_text.text(f"ğŸ“¥ Alternatif yÃ¶ntem deneniyor: {opportunity_id}...")
                    downloaded = sam.download_documents(opportunity_id, dest_dir="downloads")
            
            # Hala yoksa, opportunity details'den attachments al ve direkt iÅŸle
            if not downloaded:
                logger.info(f"ğŸ”„ Detay API'den attachments alÄ±nÄ±yor...")
                status_text.text(f"ğŸ“¥ Detay API'den attachments alÄ±nÄ±yor...")
                details = sam.get_opportunity_details(notice_id)
                if details.get('success'):
                    attachments = details.get('data', {}).get('attachments', [])
                    logger.info(f"ğŸ“ {len(attachments)} attachment bulundu (get_opportunity_details'den)")
                    
                    if attachments:
                        for att in attachments:
                            if att.get('url'):
                                try:
                                    # Ä°ndir ve iÅŸle
                                    result = sam.download_and_process_attachment(att.get('url'), att.get('title', 'document'))
                                    if result.get('success'):
                                        downloaded.append({
                                            'filename': result['data'].get('filename', 'document'),
                                            'path': result['data'].get('file_path', ''),
                                            'text': result['data'].get('text', ''),
                                            'page_count': result['data'].get('page_count', 0),
                                            'url': att.get('url'),
                                            'title': att.get('title', 'document')
                                        })
                                        logger.info(f"âœ… Ä°ÅŸlendi: {result['data'].get('filename', 'document')}")
                                except Exception as e:
                                    logger.warning(f"âš ï¸ Attachment iÅŸleme hatasÄ±: {e}")
                                    continue
                    else:
                        # Attachments yoksa, description'Ä± dÃ¶kÃ¼man olarak kullan
                        description = details.get('data', {}).get('description', '')
                        title_text = details.get('data', {}).get('title', '')
                        
                        if description or title_text:
                            logger.info(f"ğŸ“„ Attachments yok, description'Ä± dÃ¶kÃ¼man olarak kullanÄ±yorum ({len(description)} karakter)")
                            combined_text = f"{title_text}\n\n{description}".strip()
                            if combined_text:
                                downloaded.append({
                                    'filename': 'opportunity_description.txt',
                                    'path': '',
                                    'text': combined_text,
                                    'page_count': 1,
                                    'url': '',
                                    'title': 'Opportunity Description'
                                })
                                logger.info(f"âœ… Description dÃ¶kÃ¼man olarak eklendi ({len(combined_text)} karakter)")
            
            # Son Ã§are: Opportunity'nin raw_data'sÄ±ndan resourceLinks ve description Ã§Ä±kar
            if not downloaded and opportunity.get('raw_data'):
                logger.info(f"ğŸ”„ Raw data'dan resourceLinks ve description Ã§Ä±karÄ±lÄ±yor...")
                raw_data = opportunity.get('raw_data', {})
                if isinstance(raw_data, dict):
                    # Ã–nce nested raw_data'yÄ± kontrol et
                    nested_raw_data = raw_data.get('raw_data', {})
                    if nested_raw_data and isinstance(nested_raw_data, dict):
                        raw_data = nested_raw_data
                    
                    # 1. resourceLinks'ten attachments indir
                    resource_links = raw_data.get('resourceLinks', [])
                    if resource_links:
                        logger.info(f"ğŸ“ {len(resource_links)} resourceLink bulundu (raw_data'dan)")
                        for i, link in enumerate(resource_links, 1):
                            url = link if isinstance(link, str) else (link.get('url') or link.get('link') or link.get('downloadUrl') or link.get('href'))
                            if url:
                                try:
                                    title = f'Attachment {i}' if isinstance(link, str) else (link.get('title') or link.get('name') or f'Attachment {i}')
                                    result = sam.download_and_process_attachment(url, title)
                                    if result.get('success'):
                                        downloaded.append({
                                            'filename': result['data'].get('filename', title),
                                            'path': result['data'].get('file_path', ''),
                                            'text': result['data'].get('text', ''),
                                            'page_count': result['data'].get('page_count', 0),
                                            'url': url,
                                            'title': title
                                        })
                                        logger.info(f"âœ… Ä°ndirildi (raw_data'dan): {title}")
                                except Exception as e:
                                    logger.warning(f"âš ï¸ ResourceLink indirme hatasÄ±: {e}")
                    
                    # 2. Description'Ä± dÃ¶kÃ¼man olarak kullan (eÄŸer hala dÃ¶kÃ¼man yoksa)
                    if not downloaded:
                        description = raw_data.get('description', '') or raw_data.get('additionalInfoText', '') or raw_data.get('summary', '') or raw_data.get('descriptionText', '')
                        title_text = raw_data.get('title', '') or opportunity.get('title', '')
                        
                        # Description URL deÄŸilse (string ve http ile baÅŸlamÄ±yorsa)
                        if description and isinstance(description, str) and not description.startswith('http'):
                            # TÃ¼m olasÄ± alanlarÄ± kontrol et
                            all_text_parts = []
                            if title_text:
                                all_text_parts.append(title_text)
                            if description:
                                all_text_parts.append(description)
                            for key in ['additionalInfoText', 'summary', 'descriptionText', 'fullDescription', 'opportunityDescription']:
                                if raw_data.get(key) and isinstance(raw_data[key], str) and not raw_data[key].startswith('http'):
                                    all_text_parts.append(raw_data[key])
                            
                            combined_text = "\n\n".join(all_text_parts).strip()
                            
                            if combined_text:
                                downloaded.append({
                                    'filename': 'opportunity_raw_data.txt',
                                    'path': '',
                                    'text': combined_text,
                                    'page_count': max(1, len(combined_text) // 2000),
                                    'url': '',
                                    'title': 'Opportunity Raw Data'
                                })
                                logger.info(f"âœ… Raw data'dan dÃ¶kÃ¼man oluÅŸturuldu ({len(combined_text)} karakter)")
            
            # En son Ã§are: Opportunity title'Ä± bile dÃ¶kÃ¼man olarak kullan
            if not downloaded:
                logger.warning(f"âš ï¸ HiÃ§ dÃ¶kÃ¼man bulunamadÄ±, title'Ä± dÃ¶kÃ¼man olarak kullanÄ±yorum")
                title_text = opportunity.get('title', '')
                if title_text:
                    downloaded.append({
                        'filename': 'opportunity_title_only.txt',
                        'path': '',
                        'text': title_text,
                        'page_count': 1,
                        'url': '',
                        'title': 'Opportunity Title'
                    })
                    logger.info(f"âœ… Title dÃ¶kÃ¼man olarak eklendi: {title_text[:50]}...")
            
            # DÃ¶kÃ¼manlarÄ± iÅŸle
            if downloaded:
                status_text.text(f"ğŸ“„ {len(downloaded)} dÃ¶kÃ¼man iÅŸleniyor...")
                logger.info(f"ğŸ“„ {len(downloaded)} dÃ¶kÃ¼man iÅŸleniyor...")
                for doc_info in downloaded:
                    try:
                        # EÄŸer text zaten varsa (download_and_process_attachment'dan)
                        if 'text' in doc_info and doc_info.get('text'):
                            processed_doc = {
                                'filename': doc_info.get('filename', 'document'),
                                'text': doc_info.get('text', ''),
                                'page_count': doc_info.get('page_count', 0),
                                'file_path': doc_info.get('path', '')
                            }
                            logger.info(f"âœ… DÃ¶kÃ¼man zaten iÅŸlenmiÅŸ: {processed_doc['filename']} ({len(processed_doc['text'])} karakter)")
                        else:
                            # Dosya yolundan iÅŸle
                            file_path = doc_info.get('path', '')
                            if file_path and os.path.exists(file_path):
                                logger.info(f"ğŸ“„ Dosya iÅŸleniyor: {file_path}")
                                result = processor.process_file_from_path(file_path)
                                if result.get('success'):
                                    processed_doc = result['data']
                                    processed_doc['file_path'] = file_path
                                    logger.info(f"âœ… Ä°ÅŸlendi: {processed_doc.get('filename', 'document')} ({processed_doc.get('page_count', 0)} sayfa)")
                                else:
                                    logger.warning(f"âš ï¸ Ä°ÅŸleme baÅŸarÄ±sÄ±z: {file_path} - {result.get('error', 'Unknown error')}")
                                    continue
                            else:
                                logger.warning(f"âš ï¸ Dosya bulunamadÄ±: {file_path}")
                                continue
                        
                        processed_documents.append(processed_doc)
                    except Exception as e:
                        logger.warning(f"âš ï¸ DÃ¶kÃ¼man iÅŸleme hatasÄ±: {e}", exc_info=True)
                        continue
            else:
                logger.warning(f"âš ï¸ HiÃ§ dÃ¶kÃ¼man indirilemedi: {notice_id}")
                status_text.text(f"âš ï¸ DÃ¶kÃ¼man bulunamadÄ±. Bu fÄ±rsat iÃ§in ek dÃ¶kÃ¼man olmayabilir.")
        except Exception as e:
            logger.error(f"âŒ Document Processor hatasÄ±: {e}", exc_info=True)
            st.warning(f"âš ï¸ DÃ¶kÃ¼man iÅŸleme hatasÄ±: {str(e)}")
        
        # Ä°ÅŸlenen dÃ¶kÃ¼manlarÄ± gÃ¶ster + Belge tipine gÃ¶re Ã¶zelleÅŸtirilmiÅŸ analiz
        if processed_documents:
            with status_container.container():
                st.markdown("#### ğŸ“„ Ä°ÅŸlenen DokÃ¼manlar")
                
                # Form verilerini al
                form_data = st.session_state.get('form_data', {})
                llm_analyzer = LLMAnalyzer()
                
                for doc in processed_documents:
                    doc_name = doc.get('filename', 'Dosya')
                    page_count = doc.get('page_count', 0)
                    text_length = len(doc.get('text', ''))
                    
                    # Belge tipini tespit et
                    doc_type = "general"
                    doc_name_lower = doc_name.lower()
                    if "rfq" in doc_name_lower or "request" in doc_name_lower or "quote" in doc_name_lower:
                        doc_type = "rfq"
                    elif "sow" in doc_name_lower or "statement" in doc_name_lower or "work" in doc_name_lower:
                        doc_type = "sow"
                    elif "contract" in doc_name_lower or "signed" in doc_name_lower:
                        doc_type = "contract"
                    elif "far" in doc_name_lower or "52.204" in doc_name_lower:
                        doc_type = "far"
                    elif "performance" in doc_name_lower or "past" in doc_name_lower:
                        doc_type = "performance"
                    
                    # Form kriterlerine gÃ¶re Ã¶zelleÅŸtirilmiÅŸ analiz (Her kriter iÃ§in ayrÄ± tarama)
                    doc_criteria_analyses = {}
                    if form_data and form_data.get('evaluation_focus') and doc.get('text') and len(doc.get('text', '')) > 100:
                        evaluation_focus = form_data.get('evaluation_focus', [])
                        logger.info(f"ğŸ“‹ {doc_name} iÃ§in {len(evaluation_focus)} kriter bazlÄ± analiz yapÄ±lÄ±yor...")
                        
                        for criteria in evaluation_focus:
                            try:
                                # Her kriter iÃ§in Ã¶zelleÅŸtirilmiÅŸ analiz
                                criteria_analysis = llm_analyzer.analyze_document_by_criteria(
                                    doc.get('text', ''), 
                                    criteria, 
                                    form_data
                                )
                                
                                if criteria_analysis and criteria_analysis.get('success'):
                                    doc_criteria_analyses[criteria] = criteria_analysis.get('data', {})
                                    logger.info(f"âœ… {doc_name} - '{criteria}' kriteri analizi tamamlandÄ±")
                            except Exception as e:
                                logger.warning(f"âš ï¸ {doc_name} - '{criteria}' kriteri analiz hatasÄ±: {e}")
                        
                        # Belge tipine gÃ¶re genel analiz de yap (fallback)
                        try:
                            doc_analysis = llm_analyzer.analyze_document_by_type(doc.get('text', ''), doc_type, form_data)
                            if doc_analysis and doc_analysis.get('success'):
                                doc['document_analysis'] = doc_analysis.get('data', {})
                        except Exception as e:
                            logger.warning(f"âš ï¸ {doc_name} genel analiz hatasÄ±: {e}")
                        
                        # Kriter bazlÄ± analizleri dokÃ¼mana ekle
                        if doc_criteria_analyses:
                            doc['criteria_analyses'] = doc_criteria_analyses
                            logger.info(f"âœ… {doc_name} iÃ§in {len(doc_criteria_analyses)} kriter bazlÄ± analiz eklendi")
                    
                    st.markdown(f"""
                    <div style="background: rgba(15, 23, 42, 0.5); border: 1px solid var(--border-800); border-radius: 8px; padding: 12px; margin-bottom: 8px;">
                        <div style="display: flex; align-items: center; gap: 8px; margin-bottom: 8px;">
                            <span style="font-size: 16px;">ğŸ“„</span>
                            <span style="color: var(--text-300); font-size: 14px; font-weight: 500;">{doc_name}</span>
                            <span style="color: var(--text-400); font-size: 12px; margin-left: auto;">{page_count} sayfa, {text_length} karakter</span>
                        </div>
                    """, unsafe_allow_html=True)
                    
                    # Kriter bazlÄ± analiz sonuÃ§larÄ±nÄ± gÃ¶ster (Form baÅŸlÄ±klarÄ± Ã¶zelinde)
                    criteria_analyses = doc.get('criteria_analyses', {})
                    if criteria_analyses:
                        st.markdown(f"""
                        <div style="background: rgba(59, 130, 246, 0.1); border-left: 3px solid var(--blue-400); border-radius: 4px; padding: 12px; margin-top: 8px;">
                            <div style="color: var(--blue-400); font-size: 12px; font-weight: 600; margin-bottom: 8px;">ğŸ“Š Form Kriterleri BazlÄ± Analiz SonuÃ§larÄ±</div>
                        """, unsafe_allow_html=True)
                        
                        for criteria, criteria_data in criteria_analyses.items():
                            analysis = criteria_data.get('analysis', {})
                            compliance_score = analysis.get('compliance_score', 0)
                            matched_info = analysis.get('matched_info', [])
                            missing = analysis.get('missing_or_conflicting', [])
                            
                            # Kriter skoruna gÃ¶re renk
                            score_color = "var(--emerald-400)" if compliance_score >= 80 else ("var(--amber-400)" if compliance_score >= 60 else "var(--red-400)")
                            
                            st.markdown(f"""
                            <div style="background: rgba(15, 23, 42, 0.3); border-radius: 6px; padding: 10px; margin-bottom: 8px;">
                                <div style="color: var(--text-300); font-size: 11px; font-weight: 600; margin-bottom: 4px;">ğŸ¯ {criteria}</div>
                                <div style="display: flex; gap: 12px; color: var(--text-400); font-size: 10px;">
                                    <span style="color: {score_color};">Uygunluk: {compliance_score}%</span>
                                    <span>Bulunan: {len(matched_info)}</span>
                                    <span>Eksik: {len(missing)}</span>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        st.markdown("</div>", unsafe_allow_html=True)
                    elif doc.get('document_analysis'):
                        # Fallback: Genel analiz sonucu
                        analysis_data = doc.get('document_analysis', {}).get('analysis', {})
                        compliance_score = analysis_data.get('compliance_score', 0)
                        matched = analysis_data.get('matched_criteria', [])
                        missing = analysis_data.get('missing_or_conflicting', [])
                        
                        st.markdown(f"""
                        <div style="background: rgba(59, 130, 246, 0.1); border-left: 3px solid var(--blue-400); border-radius: 4px; padding: 8px; margin-top: 8px;">
                            <div style="color: var(--blue-400); font-size: 12px; font-weight: 600; margin-bottom: 4px;">ğŸ“Š Genel Analiz Sonucu</div>
                            <div style="color: var(--text-300); font-size: 11px;">Uygunluk: {compliance_score}% | EÅŸleÅŸen: {len(matched)} | Eksik: {len(missing)}</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    st.markdown("</div>", unsafe_allow_html=True)
        
        st.session_state.ai_analysis_state['completed_stages'].append(0)
        progress_bar.progress(30)
        
        # Stage 2: Compliance Analyst - DetaylÄ± uyumluluk analizi (Form verileri ile Ã¶zelleÅŸtirilmiÅŸ)
        status_text.text("ğŸ›¡ï¸ Compliance Analyst: Uyumluluk ve risk deÄŸerlendirmesi (Form kriterlerine gÃ¶re)...")
        progress_bar.progress(40)
        st.session_state.ai_analysis_state['current_stage'] = 1
        
        # Form verilerini al
        form_data = st.session_state.get('form_data', {})
        
        try:
            # TÃ¼m dÃ¶kÃ¼man metinlerini birleÅŸtir
            combined_text = "\n\n".join([doc.get('text', '') for doc in processed_documents])
            
            if combined_text:
                compliance_score = 75  # VarsayÄ±lan
                risk_level = 'medium'
                issues = []
                
                # DetaylÄ± risk analizi
                risk_keywords = {
                    'critical': ['urgent', 'immediate', 'critical', 'emergency', 'asap'],
                    'high': ['must', 'required', 'mandatory', 'shall', 'obligatory'],
                    'medium': ['should', 'recommended', 'preferred', 'desirable'],
                    'compliance': ['compliance', 'certification', 'accreditation', 'standard', 'regulation'],
                    'financial': ['bond', 'insurance', 'guarantee', 'warranty', 'penalty'],
                    'legal': ['liability', 'indemnification', 'contract', 'agreement', 'terms']
                }
                
                # Her kategori iÃ§in skor hesapla
                category_scores = {}
                for category, keywords in risk_keywords.items():
                    count = sum(1 for keyword in keywords if keyword.lower() in combined_text.lower())
                    category_scores[category] = count
                
                # Toplam risk skoru
                critical_count = category_scores.get('critical', 0)
                high_count = category_scores.get('high', 0)
                medium_count = category_scores.get('medium', 0)
                compliance_count = category_scores.get('compliance', 0)
                financial_count = category_scores.get('financial', 0)
                legal_count = category_scores.get('legal', 0)
                
                total_risk_score = (critical_count * 10) + (high_count * 5) + (medium_count * 2) + (compliance_count * 3) + (financial_count * 4) + (legal_count * 4)
                
                # Risk seviyesi belirleme
                if total_risk_score > 50 or critical_count > 5:
                    risk_level = 'high'
                    compliance_score = max(30, 100 - total_risk_score)
                    issues.append({
                        'type': 'YÃ¼ksek Risk',
                        'description': f'{critical_count} kritik, {high_count} yÃ¼ksek Ã¶ncelikli gereksinim tespit edildi',
                        'severity': 'high'
                    })
                elif total_risk_score > 25 or high_count > 10:
                    risk_level = 'medium'
                    compliance_score = max(50, 100 - total_risk_score)
                    issues.append({
                        'type': 'Orta Risk',
                        'description': f'{high_count} zorunlu gereksinim tespit edildi',
                        'severity': 'medium'
                    })
                else:
                    risk_level = 'low'
                    compliance_score = max(70, 100 - total_risk_score)
                
                # Compliance gereksinimleri
                if compliance_count > 0:
                    issues.append({
                        'type': 'Uyumluluk',
                        'description': f'{compliance_count} uyumluluk/certification gereksinimi tespit edildi',
                        'severity': 'medium'
                    })
                
                # Finansal riskler
                if financial_count > 0:
                    issues.append({
                        'type': 'Finansal',
                        'description': f'{financial_count} finansal gereksinim (bond, insurance, vb.) tespit edildi',
                        'severity': 'high'
                    })
                
                # Yasal riskler
                if legal_count > 0:
                    issues.append({
                        'type': 'Yasal',
                        'description': f'{legal_count} yasal gereksinim (liability, indemnification, vb.) tespit edildi',
                        'severity': 'high'
                    })
                
                # Form verilerine gÃ¶re compliance skorunu ayarla
                if form_data and form_data.get('evaluation_focus'):
                    # Form kriterlerine gÃ¶re ek compliance kontrolÃ¼
                    focus_items = form_data.get('evaluation_focus', [])
                    form_based_score_adjustment = 0
                    
                    # Her kriter iÃ§in kontrol
                    for focus in focus_items:
                        focus_lower = focus.lower()
                        if any(keyword in combined_text.lower() for keyword in focus_lower.split()):
                            form_based_score_adjustment += 5  # Her eÅŸleÅŸen kriter iÃ§in +5
                    
                    # Form kriterlerine gÃ¶re compliance skorunu gÃ¼ncelle
                    compliance_score = min(100, compliance_score + form_based_score_adjustment)
                    logger.info(f"ğŸ“‹ Form kriterlerine gÃ¶re compliance skoru ayarlandÄ±: {compliance_score}%")
                
                compliance_result = {
                    'score': int(compliance_score),
                    'risk_level': risk_level,
                    'issues': issues,
                    'analysis_date': datetime.now().isoformat(),
                    'documents_analyzed': len(processed_documents),
                    'category_scores': category_scores,
                    'total_risk_score': total_risk_score,
                    'form_based_analysis': bool(form_data),
                    'form_criteria_matched': len(form_data.get('evaluation_focus', [])) if form_data else 0
                }
            else:
                compliance_result = {
                    'score': 0,
                    'risk_level': 'unknown',
                    'issues': [{'type': 'UyarÄ±', 'description': 'DÃ¶kÃ¼man metni bulunamadÄ±', 'severity': 'low'}],
                    'analysis_date': datetime.now().isoformat(),
                    'documents_analyzed': len(processed_documents)
                }
        except Exception as e:
            logger.error(f"Compliance Analyst hatasÄ±: {e}", exc_info=True)
            compliance_result = {'score': 0, 'risk_level': 'unknown', 'issues': []}
        
        st.session_state.ai_analysis_state['completed_stages'].append(1)
        progress_bar.progress(60)
        
        # Stage 3: Requirements Extractor - DetaylÄ± gereksinim Ã§Ä±karÄ±mÄ± (LLM/RAG ile)
        status_text.text("ğŸ” Requirements Extractor: Gereksinimler ve kriterler analizi...")
        progress_bar.progress(70)
        st.session_state.ai_analysis_state['current_stage'] = 2
        
        try:
            if processed_documents:
                # TÃ¼m dokÃ¼man metinlerini birleÅŸtir (tam metin kullan)
                combined_text = "\n\n".join([doc.get('text', '') for doc in processed_documents if doc.get('text')])
                logger.info(f"ğŸ“„ Toplam {len(combined_text)} karakter metin birleÅŸtirildi ({len(processed_documents)} dokÃ¼mandan)")
                
                # LLM/RAG ile detaylÄ± gereksinim Ã§Ä±karÄ±mÄ±
                requirements_list = []
                
                # RAG servisi ile ilgili bÃ¶lÃ¼mleri bul - TÃœM dokÃ¼manlarÄ± kullan
                try:
                    rag_service = RAGService()
                    # TÃ¼m dokÃ¼man metinlerini RAG'e ver
                    all_doc_texts = [doc.get('text', '') for doc in processed_documents if doc.get('text')]
                    logger.info(f"ğŸ” RAG servisi {len(all_doc_texts)} dokÃ¼man ile Ã§alÄ±ÅŸÄ±yor...")
                    
                    rag_context = rag_service.retrieve_relevant_context(
                        "requirements specifications criteria standards mandatory must shall need required",
                        all_doc_texts
                    )
                    logger.info(f"âœ… RAG servisi {len(rag_context)} ilgili baÄŸlam buldu")
                except Exception as e:
                    logger.warning(f"RAG servisi hatasÄ±, basit analiz kullanÄ±lÄ±yor: {e}", exc_info=True)
                    rag_context = None
                
                # LLM Analyzer ile gereksinim Ã§Ä±karÄ±mÄ± - TÃœM metni kullan (5000 karakter limit kaldÄ±rÄ±ldÄ±)
                try:
                    llm_analyzer = LLMAnalyzer()
                    # Metin Ã§ok uzunsa, chunk'lara bÃ¶l ve her chunk'Ä± analiz et
                    max_text_length = 15000  # OpenAI iÃ§in makul limit
                    text_to_analyze = combined_text[:max_text_length] if len(combined_text) > max_text_length else combined_text
                    
                    if len(combined_text) > max_text_length:
                        logger.info(f"âš ï¸ Metin Ã§ok uzun ({len(combined_text)} karakter), ilk {max_text_length} karakter analiz ediliyor")
                    
                    logger.info(f"ğŸ¤– LLM Analyzer Ã§alÄ±ÅŸÄ±yor ({len(text_to_analyze)} karakter)...")
                    llm_result = llm_analyzer.extract_requirements(text_to_analyze, rag_context)
                    
                    if llm_result.get('success') and llm_result.get('data'):
                        req_data = llm_result['data'].get('requirements', {})
                        
                        # LLM'den gelen yapÄ±landÄ±rÄ±lmÄ±ÅŸ gereksinimleri dÃ¶nÃ¼ÅŸtÃ¼r
                        if isinstance(req_data, dict):
                            # Oda sayÄ±sÄ±
                            if req_data.get('room_count') and req_data.get('room_count') != 'belirtilmemiÅŸ':
                                requirements_list.append({
                                    'category': 'Kapasite',
                                    'requirement': f"Oda sayÄ±sÄ±: {req_data.get('room_count')}",
                                    'priority': 'YÃ¼ksek',
                                    'status': 'KarÅŸÄ±lanÄ±yor',
                                    'source': 'LLM Analizi'
                                })
                            
                            # AV gereksinimi
                            if req_data.get('av_required'):
                                requirements_list.append({
                                    'category': 'Teknik',
                                    'requirement': 'Audio-Visual (AV) ekipman gereksinimi',
                                    'priority': 'Orta',
                                    'status': 'Ä°nceleniyor',
                                    'source': 'LLM Analizi'
                                })
                            
                            # Tarih aralÄ±ÄŸÄ±
                            if req_data.get('date_range') and req_data.get('date_range') != 'belirtilmemiÅŸ':
                                requirements_list.append({
                                    'category': 'Zaman',
                                    'requirement': f"Tarih aralÄ±ÄŸÄ±: {req_data.get('date_range')}",
                                    'priority': 'YÃ¼ksek',
                                    'status': 'KarÅŸÄ±lanÄ±yor',
                                    'source': 'LLM Analizi'
                                })
                            
                            # Konum
                            if req_data.get('location') and req_data.get('location') != 'belirtilmemiÅŸ':
                                requirements_list.append({
                                    'category': 'Lokasyon',
                                    'requirement': f"Konum: {req_data.get('location')}",
                                    'priority': 'YÃ¼ksek',
                                    'status': 'KarÅŸÄ±lanÄ±yor',
                                    'source': 'LLM Analizi'
                                })
                            
                            # KÄ±sÄ±tlar
                            if req_data.get('constraints'):
                                for constraint in req_data.get('constraints', []):
                                    requirements_list.append({
                                        'category': 'KÄ±sÄ±t',
                                        'requirement': constraint,
                                        'priority': 'YÃ¼ksek',
                                        'status': 'Ä°nceleniyor',
                                        'source': 'LLM Analizi'
                                    })
                            
                            # DiÄŸer gereksinimler
                            if req_data.get('other_requirements'):
                                for other_req in req_data.get('other_requirements', []):
                                    requirements_list.append({
                                        'category': 'Genel',
                                        'requirement': other_req,
                                        'priority': 'Orta',
                                        'status': 'Ä°nceleniyor',
                                        'source': 'LLM Analizi'
                                    })
                except Exception as e:
                    logger.warning(f"LLM Analyzer hatasÄ±, pattern matching kullanÄ±lÄ±yor: {e}")
                
                # Fallback: Pattern matching (LLM yoksa veya hata verirse)
                if not requirements_list:
                    requirement_patterns = [
                        r'(?:must|shall|required|mandatory|need to|should)\s+([^\.]+)',
                        r'(?:requirement|specification|criteria|standard)\s*:?\s*([^\.]+)',
                        r'(?:minimum|maximum|at least|no more than)\s+([^\.]+)'
                    ]
                    
                    for pattern in requirement_patterns:
                        matches = re.finditer(pattern, combined_text, re.IGNORECASE)
                        for match in matches:
                            req_text = match.group(1).strip()[:200]
                            if len(req_text) > 20:
                                requirements_list.append({
                                    'category': 'Genel',
                                    'requirement': req_text,
                                    'priority': 'YÃ¼ksek' if 'must' in match.group(0).lower() or 'required' in match.group(0).lower() else 'Orta',
                                    'status': 'Ä°nceleniyor',
                                    'source': 'Pattern Matching'
                                })
                    
                    # TekrarlarÄ± kaldÄ±r
                    seen = set()
                    unique_requirements = []
                    for req in requirements_list:
                        req_key = req['requirement'][:50]
                        if req_key not in seen:
                            seen.add(req_key)
                            unique_requirements.append(req)
                    requirements_list = unique_requirements[:20]
        except Exception as e:
            logger.error(f"Requirements Extractor hatasÄ±: {e}", exc_info=True)
            requirements_list = []
        
        st.session_state.ai_analysis_state['completed_stages'].append(2)
        progress_bar.progress(85)
        
        # Stage 4: Proposal Writer - Teklif taslaÄŸÄ±
        status_text.text("âœï¸ Proposal Writer: Teklif taslaÄŸÄ± ve Ã¶neriler...")
        progress_bar.progress(90)
        st.session_state.ai_analysis_state['current_stage'] = 3
        
        try:
            # Teklif Ã¶nerileri oluÅŸtur
            recommendations = []
            if requirements_list:
                recommendations.append(f"{len(requirements_list)} adet gereksinim tespit edildi. Her birini detaylÄ± inceleyin.")
            if compliance_result.get('risk_level') == 'high':
                recommendations.append("YÃ¼ksek risk tespit edildi. Uyumluluk gereksinimlerini Ã¶nceliklendirin.")
            if processed_documents:
                recommendations.append(f"{len(processed_documents)} dÃ¶kÃ¼man analiz edildi. TÃ¼m gereksinimlerin karÅŸÄ±landÄ±ÄŸÄ±ndan emin olun.")
            
            proposal_result = {
                'status': 'Taslak',
                'recommendations': recommendations if recommendations else ['Analiz tamamlandÄ±. Teklif hazÄ±rlÄ±ÄŸÄ±na baÅŸlayabilirsiniz.'],
                'summary': f"{len(processed_documents)} dÃ¶kÃ¼man analiz edildi, {len(requirements_list)} gereksinim tespit edildi.",
                'created_at': datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"Proposal Writer hatasÄ±: {e}", exc_info=True)
            proposal_result = {'status': 'Hata', 'recommendations': []}
        
        # TamamlandÄ±
        progress_bar.progress(100)
        status_text.text("âœ… Analiz tamamlandÄ±!")
        st.session_state.ai_analysis_state['completed_stages'].append(3)
        st.session_state.ai_analysis_state['current_stage'] = 4
        st.session_state.ai_analysis_state['analysis_running'] = False
        
        # SÃ¼re hesapla
        duration = (datetime.now() - start_time).total_seconds()
        
        # Form verilerini sonuÃ§lara ekle
        form_data_final = st.session_state.get('form_data', {})
        
        # Criteria results'Ä± topla (PDF iÃ§in)
        criteria_results_for_pdf = {}
        for doc in processed_documents:
            doc_name = doc.get('filename', 'document')
            if doc.get('criteria_analyses'):
                criteria_results_for_pdf[doc_name] = doc.get('criteria_analyses', {})
        
        # SonuÃ§larÄ± oluÅŸtur - Schema: top-level metrics + detailed data
        results_data = {
            'success': True,
            'documents_processed': len(processed_documents),  # Top-level quick metric
            'requirements_count': len(requirements_list),   # Top-level quick metric
            'risk_level': compliance_result.get('risk_level', 'medium'),    # Top-level quick metric
            'duration': duration,          # Top-level quick metric
            'data': {
                'opportunity_id': notice_id,
                'analysis_completed_at': datetime.now().isoformat(),
                # Detailed data structures
                'documents': processed_documents,  # Ä°ÅŸlenen dÃ¶kÃ¼manlar
                'compliance': compliance_result,  # Compliance analysis results
                'requirements': requirements_list,  # Ã‡Ä±karÄ±lan gereksinimler
                'proposal': proposal_result,  # Proposal draft
                'form_data': form_data_final,  # Form verileri (analiz kriterleri)
                'criteria_results': criteria_results_for_pdf  # PDF iÃ§in
            }
        }
        
        st.session_state.ai_analysis_state['results'] = results_data
        
        # PDF raporu oluÅŸtur (legacy method iÃ§in)
        try:
            from pdf_report_builder import build_pdf_report
            from opportunity_runner import prepare_opportunity_folder
            
            # FÄ±rsat klasÃ¶rÃ¼nÃ¼ oluÅŸtur
            opportunity_code = opportunity.get('solicitationNumber') or notice_id or 'UNKNOWN'
            folder = prepare_opportunity_folder(".", opportunity_code)
            pdf_path = folder / "analysis_report.pdf"
            
            # Report JSON formatÄ±na Ã§evir (opportunity_requirements schema)
            report_json = {
                'opportunity_info': {
                    'solicitation_number': opportunity.get('solicitationNumber', ''),
                    'notice_id': notice_id,
                    'title': opportunity.get('title', ''),
                    'naics': opportunity.get('naicsCode', ''),
                    'response_deadline': opportunity.get('responseDeadline', '')
                },
                'event_requirements': {
                    'location': 'unknown',
                    'date_range': 'unknown',
                    'participants_min': None,
                    'participants_target': None
                },
                'commercial_terms': {},
                'compliance': compliance_result,
                'fit_assessment': {
                    'overall_score': compliance_result.get('score', 0),
                    'strengths': [],
                    'risks': [issue.get('description', '') for issue in compliance_result.get('issues', [])],
                    'blocking_issues': [],
                    'summary': f"Analysis completed. {len(processed_documents)} documents processed."
                }
            }
            
            pdf_success = build_pdf_report(
                report_json=report_json,
                output_path=str(pdf_path),
                opportunity_code=opportunity_code,
                criteria_results=criteria_results_for_pdf
            )
            
            if pdf_success:
                results_data['data']['pdf_path'] = str(pdf_path)
                logger.info(f"[OK] PDF report created: {pdf_path}")
        except Exception as e:
            logger.warning(f"[WARNING] PDF generation failed in legacy method: {e}")
        
        # VeritabanÄ±na kaydet
        try:
            from app import get_db_session
            from mergenlite_models import AIAnalysisResult
            
            db = get_db_session()
            if db:
                try:
                    # Compliance skorunu hesapla
                    compliance_score = compliance_result.get('score', 0)
                    if isinstance(compliance_score, str):
                        try:
                            compliance_score = float(compliance_score)
                        except (ValueError, TypeError):
                            compliance_score = 0
                    else:
                        compliance_score = float(compliance_score or 0)
                    
                    # Confidence hesapla (0-1 arasÄ±)
                    confidence = compliance_score / 100.0 if compliance_score > 0 else 0.5
                    
                    # AIAnalysisResult kaydet
                    ai_result = AIAnalysisResult(
                        opportunity_id=notice_id,
                        analysis_type='FULL_ANALYSIS',  # veya 'COMPLETED'
                        result=results_data,  # JSONB olarak kaydet
                        confidence=confidence,
                        timestamp=datetime.now(),
                        agent_name='MergenLite Pipeline'
                    )
                    
                    db.add(ai_result)
                    db.commit()
                    
                    logger.info(f"âœ… Analiz sonucu veritabanÄ±na kaydedildi: {ai_result.id}")
                except Exception as db_error:
                    logger.error(f"âŒ VeritabanÄ± kayÄ±t hatasÄ±: {db_error}", exc_info=True)
                    db.rollback()
                finally:
                    db.close()
        except Exception as save_error:
            logger.error(f"âŒ Analiz sonucu kaydetme hatasÄ±: {save_error}", exc_info=True)
        
        progress_container.empty()
        status_container.empty()
        st.success(f"âœ… Analiz baÅŸarÄ±yla tamamlandÄ±! {len(processed_documents)} dÃ¶kÃ¼man iÅŸlendi, {len(requirements_list)} gereksinim tespit edildi.")
        st.rerun()
        
    except Exception as e:
        st.error(f"âŒ Analiz baÅŸlatÄ±lamadÄ±: {str(e)}")
        st.session_state.ai_analysis_state['analysis_running'] = False
        import traceback
        st.exception(e)

def stop_ai_analysis():
    """AI analizini durdur"""
    st.session_state.ai_analysis_state['analysis_running'] = False
    st.info("â¹ï¸ Analiz durduruldu.")
    st.rerun()

def render_agent_results(agent: Dict[str, Any], results: Dict[str, Any]):
    """Ajan sonuÃ§larÄ±nÄ± gÃ¶ster"""
    agent_id = agent['id']
    
    # Ajan tipine gÃ¶re sonuÃ§larÄ± gÃ¶ster
    if agent_id == "document_processor":
        st.markdown("#### ğŸ“„ Ä°ÅŸlenen DokÃ¼manlar")
        docs = results.get('data', {}).get('documents', [])  # Fixed: use 'documents' not 'documents_processed'
        if docs:
            for doc in docs:
                st.write(f"- **{doc.get('filename', 'Dosya')}**: {doc.get('page_count', 0)} sayfa, {len(doc.get('text', ''))} karakter")
        else:
            st.info("Ä°ÅŸlenen dokÃ¼man bilgisi bulunamadÄ±.")
    
    elif agent_id == "compliance_analyst":
        st.markdown("#### ğŸ›¡ï¸ Uyumluluk DeÄŸerlendirmesi")
        compliance = results.get('data', {}).get('compliance', {})
        if compliance:
            score = compliance.get('score', 0)
            # Safe cast: handle None or string
            if isinstance(score, str):
                try:
                    score = int(float(score))
                except (ValueError, TypeError):
                    score = 0
            else:
                score = int(score or 0)
            st.metric("Uyumluluk Skoru", f"{score}%")
            st.write(f"**Risk Seviyesi:** {compliance.get('risk_level', 'N/A')}")
            issues = compliance.get('issues', [])
            st.write(f"**Tespit Edilen Sorunlar:** {len(issues)}")
        else:
            st.info("Uyumluluk analizi henÃ¼z tamamlanmadÄ±.")
    
    elif agent_id == "requirements_extractor":
        st.markdown("#### ğŸ” Ã‡Ä±karÄ±lan Gereksinimler")
        requirements = results.get('data', {}).get('requirements', [])
        if requirements:
            for req in requirements[:5]:  # Ä°lk 5 gereksinim
                st.write(f"- **{req.get('category', 'Genel')}**: {req.get('requirement', 'N/A')}")
            if len(requirements) > 5:
                st.caption(f"... ve {len(requirements) - 5} gereksinim daha")
        else:
            st.info("Gereksinim bilgisi bulunamadÄ±.")
    
    elif agent_id == "proposal_writer":
        st.markdown("#### âœï¸ Teklif Ã–zeti")
        proposal = results.get('data', {}).get('proposal', {})
        if proposal:
            st.write(f"**Durum:** {proposal.get('status', 'N/A')}")
            st.write(f"**Ã–neriler:** {len(proposal.get('recommendations', []))} adet")
        else:
            st.info("Teklif taslaÄŸÄ± henÃ¼z oluÅŸturulmadÄ±.")
    
    # Genel bilgiler - Expander yerine kÃ¼Ã§Ã¼k bir gÃ¶sterim
    if results.get('data'):
        st.markdown("---")
        st.caption("ğŸ“‹ Ham Veri (JSON)")
        st.json(results.get('data'))

def render_results_preview(results: Dict[str, Any]):
    """Analiz sonuÃ§larÄ±nÄ±n Ã¶nizlemesini gÃ¶ster"""
    st.markdown("---")
    st.markdown("### ğŸ“Š Analiz SonuÃ§larÄ± Ã–nizleme")
    
    if results.get('success'):
        st.success("âœ… Analiz baÅŸarÄ±yla tamamlandÄ±!")
        
        # Ã–zet metrikler
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Ä°ÅŸlenen DokÃ¼man", results.get('documents_processed', 0))
        with col2:
            st.metric("Ã‡Ä±karÄ±lan Gereksinim", results.get('requirements_count', 0))
        with col3:
            st.metric("Tespit Edilen Risk", results.get('risk_level', 'N/A'))
        with col4:
            st.metric("Analiz SÃ¼resi", f"{results.get('duration', 0):.1f}s")
        
        # DetaylÄ± sonuÃ§lar
        if results.get('data'):
            with st.expander("ğŸ“‹ DetaylÄ± SonuÃ§lar"):
                st.json(results.get('data'))
    else:
        st.error(f"âŒ Analiz hatasÄ±: {results.get('error', 'Bilinmeyen hata')}")

def render_stage_1_metadata(opportunity: Dict[str, Any]):
    """AÅŸama 1: Metadata ve DokÃ¼man Ä°ndirme"""
    
    st.markdown("---")
    
    with st.expander("ğŸ“¥ AÅŸama 1: Veri Ã‡ekme - Metadata ve DokÃ¼man Ä°ndirme", expanded=True):
        st.markdown("""
        **GÃ¶rev:** Son Teslim Tarihi, Notice ID ve Ek Dosya URL'lerinin API'den Ã§ekilmesi.
        **DoÄŸrulama:** Ä°lanÄ±n canlÄ± olduÄŸu teyit edilir.
        """)
        
        # Use Notice ID first (SAM/GSA API expects Notice ID for details endpoint)
        notice_id = opportunity.get('noticeId') or opportunity.get('solicitationNumber') or opportunity.get('opportunityId', 'N/A')
        
        if st.button("ğŸš€ Verileri Ã‡ek", key="fetch_metadata", use_container_width=True):
            with st.spinner("Metadata ve dokÃ¼manlar Ã§ekiliyor..."):
                try:
                    sam = SAMIntegration()
                    
                    # Metadata Ã§ekme
                    metadata_result = sam.get_opportunity_details(notice_id)
                    
                    if metadata_result.get('success'):
                        # Session state'e kaydet
                        st.session_state.analysis_data['metadata'] = metadata_result.get('data', {})
                        st.session_state.analysis_data['notice_id'] = notice_id
                        
                        # Metadata gÃ¶ster
                        metadata = metadata_result.get('data', {})
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("Notice ID", metadata.get('noticeId', notice_id))
                            st.metric("Son Teslim Tarihi", metadata.get('responseDeadLine', 'N/A'))
                            st.metric("YayÄ±n Tarihi", metadata.get('postedDate', 'N/A'))
                        
                        with col2:
                            st.metric("Organizasyon", metadata.get('organization', 'N/A'))
                            st.metric("NAICS Kodu", metadata.get('naicsCode', 'N/A'))
                            st.metric("Durum", "âœ… CanlÄ±" if metadata.get('active', True) else "âŒ Pasif")
                        
                        # DokÃ¼man URL'lerini gÃ¶ster
                        attachments = metadata.get('attachments', [])
                        if attachments:
                            st.markdown("### ğŸ“ Ek Dosyalar")
                            for i, att in enumerate(attachments):
                                st.write(f"**{i+1}. {att.get('title', 'Dosya')}**")
                                st.write(f"   - URL: {att.get('url', 'N/A')}")
                                st.write(f"   - Tip: {att.get('type', 'N/A')}")
                        
                        st.success("âœ… Metadata baÅŸarÄ±yla Ã§ekildi!")
                        
                        # Bir sonraki aÅŸamaya geÃ§
                        if st.button("â¡ï¸ AÅŸama 2'ye GeÃ§", key="next_stage_2"):
                            st.session_state.analysis_stage = 2
                            st.rerun()
                    else:
                        st.error(f"âŒ Hata: {metadata_result.get('error', 'Bilinmeyen hata')}")
                
                except Exception as e:
                    st.error(f"âŒ Hata: {str(e)}")
        
        # EÄŸer metadata zaten Ã§ekilmiÅŸse gÃ¶ster
        if 'metadata' in st.session_state.analysis_data:
            metadata = st.session_state.analysis_data['metadata']
            st.info("âœ… Metadata zaten Ã§ekilmiÅŸ. Bir sonraki aÅŸamaya geÃ§ebilirsiniz.")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Notice ID", metadata.get('noticeId', notice_id))
                st.metric("Son Teslim", metadata.get('responseDeadLine', 'N/A'))
            with col2:
                st.metric("Organizasyon", metadata.get('organization', 'N/A'))
                st.metric("Durum", "âœ… CanlÄ±")
            
            if st.button("â¡ï¸ AÅŸama 2'ye GeÃ§", key="next_stage_2_alt"):
                st.session_state.analysis_stage = 2
                st.rerun()

def render_stage_2_document_processing(opportunity: Dict[str, Any]):
    """AÅŸama 2: DokÃ¼man Ä°ÅŸleme - PDF/DOCX Metin Ã‡Ä±karÄ±mÄ±"""
    
    st.markdown("---")
    
    with st.expander("ğŸ“„ AÅŸama 2: DokÃ¼man Ä°ÅŸleme - PDF/DOCX Metin Ã‡Ä±karÄ±mÄ±", expanded=True):
        st.markdown("""
        **GÃ¶rev:** Unstructured ile metin Ã§Ä±karma, dosya bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ kontrolÃ¼.
        **Veri ZenginleÅŸtirme:** SOW iÃ§eriÄŸi yapÄ±landÄ±rÄ±lmaya baÅŸlanÄ±r.
        """)
        
        if 'metadata' not in st.session_state.analysis_data:
            st.warning("âš ï¸ Ã–nce AÅŸama 1'i tamamlayÄ±n.")
            return
        
        metadata = st.session_state.analysis_data['metadata']
        attachments = metadata.get('attachments', [])
        
        if not attachments:
            st.info("â„¹ï¸ Bu ilan iÃ§in ek dosya bulunamadÄ±. Manuel dosya yÃ¼kleme kullanabilirsiniz.")
            
            uploaded_file = st.file_uploader(
                "ğŸ“ Dosya YÃ¼kle (PDF, DOCX, DOC)",
                type=['pdf', 'docx', 'doc'],
                help="Ä°lan dokÃ¼manÄ±nÄ± buraya yÃ¼kleyin"
            )
            
            if uploaded_file and st.button("ğŸ“Š DosyayÄ± Ä°ÅŸle", key="process_uploaded"):
                with st.spinner("Dosya iÅŸleniyor..."):
                    try:
                        processor = DocumentProcessor()
                        result = processor.process_uploaded_file(uploaded_file)
                        
                        if result.get('success'):
                            st.session_state.analysis_data['documents'] = [result.get('data', {})]
                            st.success("âœ… Dosya baÅŸarÄ±yla iÅŸlendi!")
                            
                            # Ã‡Ä±karÄ±lan metni gÃ¶ster
                            extracted_text = result.get('data', {}).get('text', '')
                            st.text_area("ğŸ“ Ã‡Ä±karÄ±lan Metin (Ä°lk 500 karakter)", extracted_text[:500] + "...", height=150)
                            
                            if st.button("â¡ï¸ AÅŸama 3'e GeÃ§", key="next_stage_3"):
                                st.session_state.analysis_stage = 3
                                st.rerun()
                        else:
                            st.error(f"âŒ Hata: {result.get('error', 'Bilinmeyen hata')}")
                    except Exception as e:
                        st.error(f"âŒ Hata: {str(e)}")
        else:
            # DokÃ¼manlarÄ± indir ve iÅŸle
            if st.button("ğŸ“¥ DokÃ¼manlarÄ± Ä°ndir ve Ä°ÅŸle", key="download_process", use_container_width=True):
                with st.spinner("DokÃ¼manlar indiriliyor ve iÅŸleniyor..."):
                    try:
                        sam = SAMIntegration()
                        processor = DocumentProcessor()
                        
                        processed_docs = []
                        progress_bar = st.progress(0)
                        
                        for i, att in enumerate(attachments):
                            progress_bar.progress((i + 1) / len(attachments))
                            
                            url = att.get('url')
                            if url:
                                # Ä°ndir ve iÅŸle
                                result = sam.download_and_process_attachment(url, att.get('title', 'document'))
                                
                                if result.get('success'):
                                    doc_data = result.get('data', {})
                                    processed_docs.append(doc_data)
                        
                        st.session_state.analysis_data['documents'] = processed_docs
                        
                        st.success(f"âœ… {len(processed_docs)} dokÃ¼man baÅŸarÄ±yla iÅŸlendi!")
                        
                        # Ã–zet gÃ¶ster
                        for doc in processed_docs:
                            with st.expander(f"ğŸ“„ {doc.get('filename', 'Dosya')}"):
                                st.write(f"**Sayfa SayÄ±sÄ±:** {doc.get('page_count', 'N/A')}")
                                st.write(f"**Metin UzunluÄŸu:** {len(doc.get('text', ''))} karakter")
                                st.text_area("ğŸ“ Metin Ã–nizleme", doc.get('text', '')[:500] + "...", height=150, key=f"preview_{doc.get('filename')}")
                        
                        if st.button("â¡ï¸ AÅŸama 3'e GeÃ§", key="next_stage_3_download"):
                            st.session_state.analysis_stage = 3
                            st.rerun()
                    
                    except Exception as e:
                        st.error(f"âŒ Hata: {str(e)}")
        
        # EÄŸer dokÃ¼manlar zaten iÅŸlenmiÅŸse gÃ¶ster
        if 'documents' in st.session_state.analysis_data:
            st.info("âœ… DokÃ¼manlar zaten iÅŸlenmiÅŸ. Bir sonraki aÅŸamaya geÃ§ebilirsiniz.")
            
            documents = st.session_state.analysis_data['documents']
            st.write(f"**Ä°ÅŸlenen DokÃ¼man SayÄ±sÄ±:** {len(documents)}")
            
            if st.button("â¡ï¸ AÅŸama 3'e GeÃ§", key="next_stage_3_alt"):
                st.session_state.analysis_stage = 3
                st.rerun()

def render_stage_3_rag_reasoning(opportunity: Dict[str, Any]):
    """AÅŸama 3: RAG Muhakemesi - LLM ile Ã–zellik Ã‡Ä±karÄ±mÄ±"""
    
    st.markdown("---")
    
    with st.expander("ğŸ¤– AÅŸama 3: RAG Muhakemesi - LLM ile Ã–zellik Ã‡Ä±karÄ±mÄ±", expanded=True):
        st.markdown("""
        **GÃ¶rev:** LLM/Agent'Ä±n tÃ¼m metni okuyarak Oda SayÄ±sÄ±, AV ve KÄ±sÄ±tlar'Ä± (Ã¶rn. Alkol yasaÄŸÄ±) JSON formatÄ±nda Ã§Ä±karmasÄ±.
        **Kritik Bilgiler:** Ä°htiyaÃ§lar
        """)
        
        if 'documents' not in st.session_state.analysis_data:
            st.warning("âš ï¸ Ã–nce AÅŸama 2'yi tamamlayÄ±n.")
            return
        
        documents = st.session_state.analysis_data['documents']
        
        if st.button("ğŸ§  RAG Analizi BaÅŸlat", key="start_rag", use_container_width=True):
            with st.spinner("RAG analizi yapÄ±lÄ±yor... Bu biraz zaman alabilir."):
                try:
                    # RAG servisi ile analiz
                    rag_service = RAGService()
                    llm_analyzer = LLMAnalyzer()
                    
                    # TÃ¼m dokÃ¼man metinlerini birleÅŸtir
                    combined_text = "\n\n".join([doc.get('text', '') for doc in documents])
                    
                    # RAG ile ilgili bÃ¶lÃ¼mleri bul
                    rag_results = rag_service.retrieve_relevant_context(combined_text)
                    
                    # LLM ile analiz
                    analysis_result = llm_analyzer.extract_requirements(combined_text, rag_results)
                    
                    # Session state'e kaydet
                    st.session_state.analysis_data['rag_analysis'] = analysis_result
                    
                    st.success("âœ… RAG analizi tamamlandÄ±!")
                    
                    # SonuÃ§larÄ± gÃ¶ster
                    if analysis_result.get('success'):
                        requirements = analysis_result.get('data', {}).get('requirements', {})
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Oda SayÄ±sÄ±", requirements.get('room_count', 'N/A'))
                            st.metric("AV Gereksinimleri", "âœ… Var" if requirements.get('av_required', False) else "âŒ Yok")
                        
                        with col2:
                            st.metric("Tarih AralÄ±ÄŸÄ±", requirements.get('date_range', 'N/A'))
                            st.metric("Konum", requirements.get('location', 'N/A'))
                        
                        with col3:
                            constraints = requirements.get('constraints', [])
                            st.metric("KÄ±sÄ±tlar", len(constraints))
                            if constraints:
                                st.write("**KÄ±sÄ±tlar:**")
                                for constraint in constraints:
                                    st.write(f"- {constraint}")
                        
                        # DetaylÄ± JSON gÃ¶ster
                        with st.expander("ğŸ“‹ DetaylÄ± Analiz SonuÃ§larÄ± (JSON)"):
                            st.json(requirements)
                        
                        if st.button("â¡ï¸ AÅŸama 4'e GeÃ§", key="next_stage_4"):
                            st.session_state.analysis_stage = 4
                            st.rerun()
                    else:
                        st.error(f"âŒ Analiz hatasÄ±: {analysis_result.get('error', 'Bilinmeyen hata')}")
                
                except Exception as e:
                    st.error(f"âŒ Hata: {str(e)}")
                    st.exception(e)
        
        # EÄŸer analiz zaten yapÄ±lmÄ±ÅŸsa gÃ¶ster
        if 'rag_analysis' in st.session_state.analysis_data:
            st.info("âœ… RAG analizi zaten tamamlanmÄ±ÅŸ. Bir sonraki aÅŸamaya geÃ§ebilirsiniz.")
            
            analysis = st.session_state.analysis_data['rag_analysis']
            if analysis.get('success'):
                requirements = analysis.get('data', {}).get('requirements', {})
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Oda SayÄ±sÄ±", requirements.get('room_count', 'N/A'))
                    st.metric("AV Gereksinimleri", "âœ… Var" if requirements.get('av_required', False) else "âŒ Yok")
                with col2:
                    st.metric("Tarih AralÄ±ÄŸÄ±", requirements.get('date_range', 'N/A'))
                    st.metric("KÄ±sÄ±t SayÄ±sÄ±", len(requirements.get('constraints', [])))
            
            if st.button("â¡ï¸ AÅŸama 4'e GeÃ§", key="next_stage_4_alt"):
                st.session_state.analysis_stage = 4
                st.rerun()

def render_stage_4_final_report(opportunity: Dict[str, Any]):
    """AÅŸama 4: Final Rapor"""
    
    st.markdown("---")
    
    with st.expander("ğŸ“Š AÅŸama 4: Final Rapor", expanded=True):
        st.markdown("""
        **GÃ¶rev:** TÃ¼m analiz sonuÃ§larÄ±nÄ±n Ã¶zetlenmesi ve kullanÄ±cÄ±ya sunulmasÄ±.
        """)
        
        if 'rag_analysis' not in st.session_state.analysis_data:
            st.warning("âš ï¸ Ã–nce AÅŸama 3'Ã¼ tamamlayÄ±n.")
            return
        
        # Rapor oluÅŸtur
        if st.button("ğŸ“„ Final Raporu OluÅŸtur", key="generate_report", use_container_width=True):
            with st.spinner("Rapor oluÅŸturuluyor..."):
                try:
                    report = generate_final_report(opportunity, st.session_state.analysis_data)
                    st.session_state.analysis_data['final_report'] = report
                    
                    st.success("âœ… Final rapor oluÅŸturuldu!")
                
                except Exception as e:
                    st.error(f"âŒ Hata: {str(e)}")
        
        # Raporu gÃ¶ster
        if 'final_report' in st.session_state.analysis_data:
            report = st.session_state.analysis_data['final_report']
            
            st.markdown("## ğŸ“Š Final Analiz Raporu")
            
            # Ã–zet
            st.markdown("### ğŸ“‹ Ã–zet")
            st.markdown(report.get('summary', 'Ã–zet bulunamadÄ±.'))
            
            # Ana Bulgular
            st.markdown("### ğŸ” Ana Bulgular")
            findings = report.get('findings', [])
            for i, finding in enumerate(findings, 1):
                st.write(f"{i}. {finding}")
            
            # Ã–neriler
            st.markdown("### ğŸ’¡ Ã–neriler")
            recommendations = report.get('recommendations', [])
            for i, rec in enumerate(recommendations, 1):
                st.write(f"{i}. {rec}")
            
            # DetaylÄ± Veriler
            st.markdown("### ğŸ“ˆ DetaylÄ± Veriler")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### Metadata")
                metadata = st.session_state.analysis_data.get('metadata', {})
                st.json(metadata)
            
            with col2:
                st.markdown("#### Gereksinimler")
                requirements = st.session_state.analysis_data.get('rag_analysis', {}).get('data', {}).get('requirements', {})
                st.json(requirements)
            
            # Ä°ndirme butonu
            st.markdown("---")
            report_json = json.dumps(report, indent=2, ensure_ascii=False)
            st.download_button(
                label="ğŸ“¥ Raporu Ä°ndir (JSON)",
                data=report_json,
                file_name=f"mergen_analysis_{opportunity.get('opportunityId', 'report')}.json",
                mime="application/json"
            )
        else:
            st.info("â„¹ï¸ Final raporu oluÅŸturmak iÃ§in butona tÄ±klayÄ±n.")

def generate_final_report(opportunity: Dict[str, Any], analysis_data: Dict[str, Any]) -> Dict[str, Any]:
    """Final raporu oluÅŸtur"""
    
    metadata = analysis_data.get('metadata', {})
    requirements = analysis_data.get('rag_analysis', {}).get('data', {}).get('requirements', {})
    documents = analysis_data.get('documents', [])
    
    report = {
        'opportunity_id': opportunity.get('opportunityId', 'N/A'),
        'title': opportunity.get('title', 'N/A'),
        'generated_at': datetime.now().isoformat(),
        'summary': f"""
        Bu analiz, {opportunity.get('opportunityId', 'N/A')} numaralÄ± ilan iÃ§in gerÃ§ekleÅŸtirilmiÅŸtir.
        {len(documents)} dokÃ¼man iÅŸlenmiÅŸ ve RAG analizi ile gereksinimler Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.
        """,
        'findings': [
            f"Oda gereksinimi: {requirements.get('room_count', 'BelirtilmemiÅŸ')}",
            f"AV gereksinimleri: {'Var' if requirements.get('av_required', False) else 'Yok'}",
            f"Tarih aralÄ±ÄŸÄ±: {requirements.get('date_range', 'BelirtilmemiÅŸ')}",
            f"Tespit edilen kÄ±sÄ±t sayÄ±sÄ±: {len(requirements.get('constraints', []))}"
        ],
        'recommendations': [
            "Gereksinimlerin tam karÅŸÄ±landÄ±ÄŸÄ±ndan emin olun",
            "KÄ±sÄ±tlarÄ±n dikkate alÄ±ndÄ±ÄŸÄ±ndan emin olun",
            "Tarih aralÄ±ÄŸÄ±nÄ±n uygunluÄŸunu kontrol edin"
        ],
        'metadata': metadata,
        'requirements': requirements,
        'document_count': len(documents)
    }
    
    return report

